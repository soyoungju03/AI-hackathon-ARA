"""
AI Research Assistant - ë©”ì¸ ì§„ì…ì 
====================================

ì´ íŒŒì¼ì€ Hugging Face Spacesì—ì„œ ì•±ì„ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ë©”ì¸ ì§„ì…ì ì…ë‹ˆë‹¤.

Hugging Face Spaces ë°°í¬ ì‹œ ì£¼ì˜ì‚¬í•­:
-------------------------------------
1. íŒŒì¼ëª…ì´ ë°˜ë“œì‹œ app.pyì—¬ì•¼ í•©ë‹ˆë‹¤
2. í™˜ê²½ ë³€ìˆ˜ëŠ” Spacesì˜ Settings > Repository secretsì—ì„œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤
3. requirements.txtì— ëª¨ë“  ì˜ì¡´ì„±ì´ í¬í•¨ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤

í˜„ì¬ ë°œìƒí•œ ì—ëŸ¬ í•´ê²°:
----------------------
ê¸°ì¡´ ì—ëŸ¬: "OPENAI_API_KEY must be set"
í•´ê²°: os.getenv()ë¡œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ì½ì–´ì˜¤ë˜, ì—†ìœ¼ë©´ ì ì ˆí•œ ì—ëŸ¬ ë©”ì‹œì§€ í‘œì‹œ
"""

import os
import sys

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
# ì´ë ‡ê²Œ í•´ì•¼ app.graph, app.tools ë“±ì˜ ëª¨ë“ˆì„ importí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

import gradio as gr
from typing import List, Tuple
import uuid

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (ë¡œì»¬ ê°œë°œìš©)
from dotenv import load_dotenv
load_dotenv()


# ============================================
# í™˜ê²½ ë³€ìˆ˜ ê²€ì¦
# ============================================

def check_api_key():
    """
    OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
    
    Hugging Face Spacesì—ì„œëŠ” Settings > Repository secretsì—ì„œ
    OPENAI_API_KEYë¥¼ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.
    """
    api_key = os.getenv("OPENAI_API_KEY")
    
    if not api_key:
        return False, """
        âš ï¸ **OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.**
        
        **Hugging Face Spaces ì‚¬ìš©ì:**
        1. Settings íƒ­ìœ¼ë¡œ ì´ë™
        2. Repository secrets ì„¹ì…˜ ì°¾ê¸°
        3. `OPENAI_API_KEY`ë¥¼ ì´ë¦„ìœ¼ë¡œ, API í‚¤ë¥¼ ê°’ìœ¼ë¡œ ì¶”ê°€
        4. Spaceë¥¼ ë‹¤ì‹œ ì‹œì‘
        
        **ë¡œì»¬ ê°œë°œì:**
        1. í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— `.env` íŒŒì¼ ìƒì„±
        2. `OPENAI_API_KEY=sk-your-key-here` ì¶”ê°€
        """
    
    return True, api_key


# ============================================
# ê°„ë‹¨í•œ ê²€ìƒ‰ í•¨ìˆ˜ (API í‚¤ ì—†ì´ë„ UI í‘œì‹œìš©)
# ============================================

# ì „ì—­ ìƒíƒœ
session_data = {}


def process_chat_message(
    message: str,
    history: List[Tuple[str, str]],
    state: dict
) -> Tuple[str, List[Tuple[str, str]], dict]:
    """
    ì±„íŒ… ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    LangGraph ì›Œí¬í”Œë¡œìš°ì™€ í†µí•©ë˜ì–´ Human-in-the-Loopì„ ì§€ì›í•©ë‹ˆë‹¤.
    """
    
    if not message.strip():
        return "", history, state
    
    # API í‚¤ í™•ì¸
    has_key, key_or_message = check_api_key()
    
    if not has_key:
        history.append((message, key_or_message))
        return "", history, state
    
    # ì„¸ì…˜ ID ì„¤ì •
    if "session_id" not in state or state["session_id"] is None:
        state["session_id"] = str(uuid.uuid4())
    
    session_id = state["session_id"]
    
    try:
        # LangGraph ì›Œí¬í”Œë¡œìš° ì„í¬íŠ¸ (API í‚¤ê°€ ìˆì„ ë•Œë§Œ)
        from app.graph.workflow import ResearchAssistant
        
        # ì„¸ì…˜ë³„ ì–´ì‹œìŠ¤í„´íŠ¸ ê´€ë¦¬
        if session_id not in session_data:
            session_data[session_id] = {
                "assistant": ResearchAssistant(),
                "waiting": False
            }
        
        session = session_data[session_id]
        assistant = session["assistant"]
        waiting = session.get("waiting", False)
        
        if waiting:
            # Interrupt ì‘ë‹µ ì²˜ë¦¬
            result = assistant.continue_with_response(message)
            
            if result["status"] == "completed":
                response = result["response"]
                session["waiting"] = False
            elif result["status"] == "waiting_for_input":
                response = result["message"]
            else:
                response = f"âŒ ì˜¤ë¥˜: {result.get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}"
                session["waiting"] = False
        
        else:
            # ìƒˆ ì§ˆë¬¸ ì²˜ë¦¬
            result = assistant.start(message, session_id)
            
            if result["status"] == "waiting_for_input":
                keywords = result.get("keywords", [])
                response = result["message"]
                
                if keywords:
                    response += f"\n\n**ğŸ”‘ ì¶”ì¶œëœ í‚¤ì›Œë“œ**: {', '.join(keywords)}"
                response += "\n\n---\nğŸ“Š **ê²€ìƒ‰í•  ë…¼ë¬¸ ìˆ˜ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš” (1-10):**"
                
                session["waiting"] = True
                
            elif result["status"] == "completed":
                response = result["response"]
            else:
                response = f"âŒ ì˜¤ë¥˜: {result.get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}"
        
        history.append((message, response))
        
    except ImportError as e:
        error_msg = f"""
        âŒ **ëª¨ë“ˆ ì„í¬íŠ¸ ì˜¤ë¥˜**
        
        í•„ìš”í•œ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {str(e)}
        
        requirements.txtë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.
        """
        history.append((message, error_msg))
    
    except Exception as e:
        error_msg = f"âŒ **ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤**: {str(e)}"
        history.append((message, error_msg))
    
    return "", history, state


def quick_search(question: str, paper_count: int) -> str:
    """ë¹ ë¥¸ ê²€ìƒ‰ - Human-in-the-Loop ì—†ì´ ë°”ë¡œ ì‹¤í–‰"""
    
    if not question.strip():
        return "âŒ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."
    
    has_key, key_or_message = check_api_key()
    if not has_key:
        return key_or_message
    
    try:
        from app.graph.workflow import ResearchAssistant
        
        assistant = ResearchAssistant()
        response = assistant.run(question, paper_count=int(paper_count))
        return response
        
    except Exception as e:
        return f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


# ============================================
# Gradio ì¸í„°í˜ì´ìŠ¤
# ============================================

def create_app():
    """Gradio ì•±ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    
    theme = gr.themes.Soft(
        primary_hue="blue",
        secondary_hue="slate",
    )
    
    with gr.Blocks(
        title="ğŸ“š AI Research Assistant",
        theme=theme,
        css="""
        .container { max-width: 1200px; margin: auto; }
        footer { display: none !important; }
        """
    ) as demo:
        
        # í—¤ë”
        gr.Markdown("""
        # ğŸ“š AI Research Assistant
        ### í•™ìˆ  ë…¼ë¬¸ ê¸°ë°˜ ì§€ëŠ¥í˜• ì—°êµ¬ ë„ìš°ë¯¸
        
        **ğŸ”§ ê¸°ìˆ  ìŠ¤íƒ**: LangGraph + ReAct Pattern + Human-in-the-Loop + arXiv API
        
        ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ AIê°€ ê´€ë ¨ ë…¼ë¬¸ì„ ê²€ìƒ‰í•˜ê³  í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•´ë“œë¦½ë‹ˆë‹¤.
        
        ---
        """)
        
        with gr.Tabs():
            
            # íƒ­ 1: ëŒ€í™”í˜• ê²€ìƒ‰
            with gr.Tab("ğŸ’¬ ëŒ€í™”í˜• ê²€ìƒ‰"):
                
                gr.Markdown("""
                **ğŸ”„ Human-in-the-Loop ì›Œí¬í”Œë¡œìš°:**
                1. ì—°êµ¬ ì§ˆë¬¸ ì…ë ¥ â†’ 2. AI í‚¤ì›Œë“œ ë¶„ì„ â†’ 3. **ë…¼ë¬¸ ìˆ˜ ì„ íƒ** â†’ 4. ê²€ìƒ‰ ë° ìš”ì•½
                """)
                
                state = gr.State({
                    "session_id": None,
                    "waiting": False
                })
                
                chatbot = gr.Chatbot(
                    height=450,
                    show_label=False,
                    bubble_full_width=False,
                    avatar_images=(None, "https://em-content.zobj.net/source/twitter/376/robot_1f916.png")
                )
                
                with gr.Row():
                    msg_input = gr.Textbox(
                        placeholder="ì—°êµ¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”... (ì˜ˆ: ììœ¨ì£¼í–‰ LiDAR ì„¼ì„œ ê¸°ìˆ )",
                        lines=2,
                        scale=4,
                        show_label=False
                    )
                    send_btn = gr.Button("ì „ì†¡", variant="primary", scale=1)
                
                with gr.Row():
                    clear_btn = gr.Button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”", size="sm")
                
                gr.Examples(
                    examples=[
                        "ììœ¨ì£¼í–‰ ìë™ì°¨ì˜ LiDAR ì„¼ì„œ ë°ì´í„° ì²˜ë¦¬ ìµœì‹  ê¸°ë²•",
                        "Transformer ëª¨ë¸ì˜ attention ë©”ì»¤ë‹ˆì¦˜ ì—°êµ¬",
                        "ë”¥ëŸ¬ë‹ ê¸°ë°˜ ì˜ë£Œ ì˜ìƒ ë¶„ì„",
                        "ê°•í™”í•™ìŠµì„ í™œìš©í•œ ë¡œë´‡ ì œì–´",
                        "Graph Neural Network ì‘ìš© ì—°êµ¬",
                    ],
                    inputs=msg_input,
                    label="ğŸ’¡ ì˜ˆì‹œ ì§ˆë¬¸"
                )
                
                # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
                send_btn.click(
                    process_chat_message,
                    inputs=[msg_input, chatbot, state],
                    outputs=[msg_input, chatbot, state]
                )
                
                msg_input.submit(
                    process_chat_message,
                    inputs=[msg_input, chatbot, state],
                    outputs=[msg_input, chatbot, state]
                )
                
                clear_btn.click(
                    lambda: ([], {"session_id": None, "waiting": False}),
                    outputs=[chatbot, state]
                )
            
            # íƒ­ 2: ë¹ ë¥¸ ê²€ìƒ‰
            with gr.Tab("ğŸ” ë¹ ë¥¸ ê²€ìƒ‰"):
                
                gr.Markdown("""
                **ë¹ ë¥¸ ê²€ìƒ‰**: ë…¼ë¬¸ ìˆ˜ë¥¼ ë¯¸ë¦¬ ì„ íƒí•˜ê³  ë°”ë¡œ ê²€ìƒ‰ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
                """)
                
                with gr.Row():
                    with gr.Column(scale=3):
                        quick_input = gr.Textbox(
                            label="ğŸ“ ì—°êµ¬ ì§ˆë¬¸",
                            placeholder="ê²€ìƒ‰í•˜ê³  ì‹¶ì€ ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”...",
                            lines=3
                        )
                    
                    with gr.Column(scale=1):
                        paper_slider = gr.Slider(
                            minimum=1,
                            maximum=10,
                            value=3,
                            step=1,
                            label="ğŸ”¢ ë…¼ë¬¸ ìˆ˜"
                        )
                        search_btn = gr.Button("ğŸ” ê²€ìƒ‰", variant="primary", size="lg")
                
                quick_output = gr.Markdown(value="*ê²€ìƒ‰ ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤*")
                
                search_btn.click(
                    quick_search,
                    inputs=[quick_input, paper_slider],
                    outputs=quick_output
                )
            
            # íƒ­ 3: ì‹œìŠ¤í…œ ì •ë³´
            with gr.Tab("â„¹ï¸ ì •ë³´"):
                
                # API í‚¤ ìƒíƒœ í™•ì¸
                has_key, _ = check_api_key()
                status_emoji = "âœ…" if has_key else "âŒ"
                status_text = "ì„¤ì •ë¨" if has_key else "ì„¤ì • í•„ìš”"
                
                gr.Markdown(f"""
                ## ğŸ“– ì‹œìŠ¤í…œ ì •ë³´
                
                ### API ìƒíƒœ
                - **OpenAI API Key**: {status_emoji} {status_text}
                
                ### âœ¨ ì£¼ìš” ê¸°ëŠ¥
                
                | ê¸°ëŠ¥ | ì„¤ëª… |
                |------|------|
                | ì§ˆë¬¸ ë¶„ì„ | AIê°€ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ |
                | Human-in-the-Loop | ì‚¬ìš©ìê°€ ê²€ìƒ‰ ì„¤ì •ì„ í™•ì¸/ì¡°ì • |
                | ë…¼ë¬¸ ê²€ìƒ‰ | arXivì—ì„œ ê´€ë ¨ ë…¼ë¬¸ ê²€ìƒ‰ |
                | ì—°ê´€ì„± í‰ê°€ | ê²€ìƒ‰ ê²°ê³¼ í’ˆì§ˆ í•„í„°ë§ |
                | ìš”ì•½ ìƒì„± | êµ¬ì¡°í™”ëœ ë…¼ë¬¸ ìš”ì•½ |
                
                ### ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ
                
                - **LangGraph**: ì›Œí¬í”Œë¡œìš° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
                - **ReAct íŒ¨í„´**: Thought-Action-Observation êµ¬ì¡°
                - **OpenAI GPT-4o**: ì§ˆë¬¸ ë¶„ì„ ë° ìš”ì•½
                - **arXiv API**: ë…¼ë¬¸ ê²€ìƒ‰
                - **Gradio**: ì›¹ ì¸í„°í˜ì´ìŠ¤
                
                ### ğŸ”„ ReAct ì›Œí¬í”Œë¡œìš°
                
                ```
                [Thought] ì§ˆë¬¸ ë¶„ì„: "ììœ¨ì£¼í–‰ LiDAR ê¸°ìˆ ì— ëŒ€í•´ ì•Œê³  ì‹¶ì–´í•¨"
                    â†“
                [Action] í‚¤ì›Œë“œ ì¶”ì¶œ: ["autonomous driving", "LiDAR", "sensor"]
                    â†“
                [INTERRUPT] ì‚¬ìš©ìì—ê²Œ ë…¼ë¬¸ ìˆ˜ í™•ì¸ ìš”ì²­
                    â†“
                [Action] arXiv ê²€ìƒ‰ ì‹¤í–‰
                    â†“
                [Observation] 5ê°œ ë…¼ë¬¸ ë°œê²¬, ì—°ê´€ì„± í‰ê°€
                    â†“
                [Action] ê³ ì—°ê´€ì„± ë…¼ë¬¸ ìš”ì•½ ìƒì„±
                    â†“
                [Output] ìµœì¢… ì‘ë‹µ ì œê³µ
                ```
                
                ---
                
                **ë²„ì „**: 2.0 | **ê°œë°œ**: AI Hackathon Project
                """)
        
        # í‘¸í„°
        gr.Markdown("""
        ---
        <center>
        Made with â¤ï¸ using LangGraph + Gradio | 
        ğŸ“š <a href="https://arxiv.org" target="_blank">arXiv</a> | 
        ğŸ”— <a href="https://github.com" target="_blank">GitHub</a>
        </center>
        """)
    
    return demo


# ============================================
# ì•± ì‹¤í–‰
# ============================================

# Gradio ì•± ìƒì„±
demo = create_app()

# Hugging Face Spacesì—ì„œ ì‹¤í–‰ë  ë•Œ
if __name__ == "__main__":
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False
    )
