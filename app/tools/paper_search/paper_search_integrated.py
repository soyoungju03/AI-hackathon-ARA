"""
í†µí•© ê²€ìƒ‰ ëª¨ë“ˆ: arXiv + RISS ë©€í‹°ì†ŒìŠ¤ ê²€ìƒ‰
============================================

ë‹¹ì‹ ì˜ workflowì˜ search_papers_nodeë¥¼ ìˆ˜ì •í•˜ì—¬
arXivì™€ RISSì—ì„œ ë™ì‹œì— ë…¼ë¬¸ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.

í•µì‹¬ ì•„ì´ë””ì–´:
1. ë‘ ì†ŒìŠ¤ì— ë™ì‹œì— ê²€ìƒ‰ ìš”ì²­ì„ ë³´ëƒ…ë‹ˆë‹¤
2. ê²°ê³¼ë¥¼ ë™ì¼í•œ Paper í˜•ì‹ìœ¼ë¡œ í†µì¼í•©ë‹ˆë‹¤
3. ì¶œì²˜(source)ë¡œ ì–´ëŠ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì™”ëŠ”ì§€ í‘œì‹œí•©ë‹ˆë‹¤
4. ê²°ê³¼ë¥¼ ê²°í•©í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤

ì´ë ‡ê²Œ í•˜ë©´ ì‚¬ìš©ì ì…ì¥ì—ì„œëŠ” í†µí•©ëœ í•˜ë‚˜ì˜ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°›ê²Œ ë©ë‹ˆë‹¤.
"""

import asyncio
import logging
from typing import List, Tuple, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime

from app.graph.state import Paper, AgentState, ReActStep
from app.config import get_settings

# arXiv ê²€ìƒ‰ import
try:
    from app.tools.paper_search.arxiv_tool import search_arxiv
except ImportError:
    search_arxiv = None

# RISS ê²€ìƒ‰ import (ì•„ì§ ì—†ìœ¼ë©´ None)
try:
    from app.tools.paper_search.riss_client import RissClient
    riss_available = True
except ImportError:
    riss_available = False
    RissClient = None

logger = logging.getLogger(__name__)
settings = get_settings()


class MultiSourcePaperSearcher:
    """
    arXivì™€ RISSë¥¼ í†µí•©í•˜ì—¬ ê²€ìƒ‰í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    
    ì´ í´ë˜ìŠ¤ëŠ” ë‘ ì†ŒìŠ¤ì— ë³‘ë ¬ë¡œ ê²€ìƒ‰ ìš”ì²­ì„ ë³´ë‚´ê³ ,
    ê²°ê³¼ë¥¼ ë™ì¼í•œ Paper í˜•ì‹ìœ¼ë¡œ í†µì¼í•©ë‹ˆë‹¤.
    """
    
    def __init__(self):
        """ë©€í‹°ì†ŒìŠ¤ ê²€ìƒ‰ê¸°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        self.riss_client = None
        
        # RISS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ì„ íƒì‚¬í•­)
        if riss_available:
            try:
                self.riss_client = RissClient(max_results_per_query=100, delay=2)
                logger.info("âœ“ RISS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                logger.warning(f"RISS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
                self.riss_client = None
        else:
            logger.warning("RISS í´ë¼ì´ì–¸íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (beautifulsoup4 ë¯¸ì„¤ì¹˜)")
    
    def search(
        self,
        keywords: List[str],
        max_results: int = 5,
        domain: Optional[str] = None,
        sources: Optional[List[str]] = None
    ) -> List[Paper]:
        """
        ë©€í‹°ì†ŒìŠ¤ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        
        Args:
            keywords: ê²€ìƒ‰ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
            max_results: ì†ŒìŠ¤ë‹¹ ìµœëŒ€ ê²°ê³¼ ìˆ˜
            domain: ê²€ìƒ‰ ë„ë©”ì¸ (arXivìš©)
            sources: ê²€ìƒ‰í•  ì†ŒìŠ¤ ë¦¬ìŠ¤íŠ¸
                    ["arxiv", "riss"]
                    ê¸°ë³¸ê°’: ["arxiv"] (ë¹ ë¥¸ ê²€ìƒ‰)
                    ì›í•˜ë©´ ["arxiv", "riss"]ë¡œ ì„¤ì •
        
        Returns:
            í†µí•©ëœ Paper ê°ì²´ ë¦¬ìŠ¤íŠ¸
        """
        
        if sources is None:
            # ê¸°ë³¸ê°’: arXivë§Œ ê²€ìƒ‰ (ë¹ ë¦„)
            # RISSëŠ” ëŠë¦´ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, í•„ìš”ì‹œì—ë§Œ ì¶”ê°€
            sources = ["arxiv"]
        
        logger.info(f"ë©€í‹°ì†ŒìŠ¤ ê²€ìƒ‰ ì‹œì‘")
        logger.info(f"  - í‚¤ì›Œë“œ: {keywords}")
        logger.info(f"  - ì†ŒìŠ¤: {sources}")
        logger.info(f"  - ê²°ê³¼ ìˆ˜: {max_results}ê°œ/ì†ŒìŠ¤")
        
        all_papers = []
        
        # ìŠ¤ë ˆë“œ í’€ì„ ì‚¬ìš©í•˜ì—¬ ë³‘ë ¬ ê²€ìƒ‰ ìˆ˜í–‰
        with ThreadPoolExecutor(max_workers=len(sources)) as executor:
            futures = {}
            
            # arXiv ê²€ìƒ‰
            if "arxiv" in sources and search_arxiv:
                logger.info("arXiv ê²€ìƒ‰ ì¤‘...")
                future = executor.submit(
                    self._search_arxiv,
                    keywords=keywords,
                    max_results=max_results,
                    domain=domain
                )
                futures[future] = "arxiv"
            
            # RISS ê²€ìƒ‰
            if "riss" in sources and self.riss_client:
                logger.info("RISS ê²€ìƒ‰ ì¤‘...")
                future = executor.submit(
                    self._search_riss,
                    keywords=keywords,
                    max_results=max_results
                )
                futures[future] = "riss"
            
            # ê²°ê³¼ ìˆ˜ì§‘
            for future in as_completed(futures):
                source_name = futures[future]
                try:
                    papers = future.result()
                    logger.info(f"âœ“ {source_name.upper()} ê²€ìƒ‰ ì™„ë£Œ: {len(papers)}ê°œ")
                    all_papers.extend(papers)
                except Exception as e:
                    logger.error(f"âŒ {source_name.upper()} ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
        
        logger.info(f"âœ“ ë©€í‹°ì†ŒìŠ¤ ê²€ìƒ‰ ì™„ë£Œ: ì´ {len(all_papers)}ê°œ ë…¼ë¬¸")
        
        return all_papers
    
    def _search_arxiv(
        self,
        keywords: List[str],
        max_results: int,
        domain: Optional[str] = None
    ) -> List[Paper]:
        """
        arXivì—ì„œ ê²€ìƒ‰í•˜ì—¬ Paper ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        ë‹¹ì‹ ì˜ ê¸°ì¡´ search_arxiv í•¨ìˆ˜ì™€ í˜¸í™˜ë©ë‹ˆë‹¤.
        """
        
        try:
            # ë‹¹ì‹ ì˜ ê¸°ì¡´ search_arxiv í•¨ìˆ˜ í˜¸ì¶œ
            arxiv_papers = search_arxiv(
                keywords=keywords,
                max_results=max_results,
                domain=domain
            )
            
            # ì´ë¯¸ Paper ê°ì²´ì¼ ê°€ëŠ¥ì„±ì´ ë†’ì§€ë§Œ, í˜¹ì‹œ ëª¨ë¥´ë‹ˆ í™•ì¸
            if arxiv_papers and isinstance(arxiv_papers[0], dict):
                # ë”•ì…”ë„ˆë¦¬ë¥¼ Paper ê°ì²´ë¡œ ë³€í™˜
                papers = [
                    Paper(
                        title=p.get('title', ''),
                        authors=p.get('authors', []),
                        abstract=p.get('abstract', ''),
                        url=p.get('url', ''),
                        published_date=p.get('published_date', ''),
                        source='arXiv',
                        relevance_score=p.get('relevance_score', 0.0)
                    )
                    for p in arxiv_papers
                ]
            else:
                # ì´ë¯¸ Paper ê°ì²´
                papers = arxiv_papers
                # source í•„ë“œë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •
                for paper in papers:
                    paper.source = 'arXiv'
            
            return papers
        
        except Exception as e:
            logger.error(f"arXiv ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def _search_riss(
        self,
        keywords: List[str],
        max_results: int
    ) -> List[Paper]:
        """
        RISSì—ì„œ ê²€ìƒ‰í•˜ì—¬ Paper ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        RISS ê²°ê³¼ë¥¼ Paper í˜•ì‹ìœ¼ë¡œ í†µì¼í•©ë‹ˆë‹¤.
        """
        
        if not self.riss_client:
            logger.warning("RISS í´ë¼ì´ì–¸íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return []
        
        try:
            # RISSì—ì„œ í•œêµ­ ë…¼ë¬¸ ê²€ìƒ‰ (ìš°ì„ ì ìœ¼ë¡œ í•œêµ­ì–´ ë…¼ë¬¸ ê²€ìƒ‰)
            riss_papers, total = self.riss_client.search_by_keyword(
                keywords=keywords,
                max_results=max_results,
                search_type="all"  # êµ­ë¬¸ê³¼ ì˜ë¬¸ ëª¨ë‘
            )
            
            # RISS ê²°ê³¼ë¥¼ Paper í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            papers = []
            for riss_paper in riss_papers:
                paper = Paper(
                    title=riss_paper.get('title', ''),
                    authors=riss_paper.get('authors', []),
                    abstract=riss_paper.get('abstract', ''),
                    url=riss_paper.get('url', ''),
                    published_date=riss_paper.get('published_date', ''),
                    source='RISS',  # ì¶œì²˜ í‘œì‹œ
                    relevance_score=0.0  # RISSì—ì„œëŠ” ì ìˆ˜ë¥¼ ì§ì ‘ ì œê³µí•˜ì§€ ì•ŠìŒ
                )
                papers.append(paper)
            
            return papers
        
        except Exception as e:
            logger.error(f"RISS ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return []


# ì „ì—­ ê²€ìƒ‰ê¸° ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤)
_searcher = None

def get_multi_source_searcher() -> MultiSourcePaperSearcher:
    """ë©€í‹°ì†ŒìŠ¤ ê²€ìƒ‰ê¸° ì¸ìŠ¤í„´ìŠ¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    global _searcher
    if _searcher is None:
        _searcher = MultiSourcePaperSearcher()
    return _searcher


# ============================================
# ìˆ˜ì •ëœ search_papers_node
# ============================================

def search_papers_node(state: AgentState) -> dict:
    """
    ìˆ˜ì •ëœ search_papers_node: arXiv + RISS í†µí•© ê²€ìƒ‰
    
    ì´ ë…¸ë“œëŠ” ë‹¹ì‹ ì˜ ê¸°ì¡´ search_papers_nodeë¥¼ ëŒ€ì²´í•©ë‹ˆë‹¤.
    arXivì™€ RISSì—ì„œ ë™ì‹œì— ë…¼ë¬¸ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    Args:
        state: AgentState ê°ì²´
    
    Returns:
        ìƒíƒœ ì—…ë°ì´íŠ¸ ë”•ì…”ë„ˆë¦¬
    """
    
    keywords = state.get("extracted_keywords", [])
    paper_count = state.get("paper_count", 3)
    domain = state.get("question_domain", None)
    
    # ê¸°ë³¸ê°’: arXivë§Œ ê²€ìƒ‰ (ë¹ ë¦„)
    # í•„ìš”ì‹œ ["arxiv", "riss"]ë¡œ ë³€ê²½ ê°€ëŠ¥
    sources_to_search = ["arxiv"]
    
    # ë™ì‘ ì„¤ëª…
    action_content = f"""ë…¼ë¬¸ ê²€ìƒ‰ì„ ì‹¤í–‰í•©ë‹ˆë‹¤:
- í‚¤ì›Œë“œ: {', '.join(keywords)}
- ê²€ìƒ‰ ê°œìˆ˜: {paper_count}ê°œ
- ë„ë©”ì¸: {domain or 'ì „ì²´'}
- ê²€ìƒ‰ ì†ŒìŠ¤: {', '.join(sources_to_search)}"""
    
    action_step = ReActStep(
        step_type="action",
        content=action_content
    )
    
    try:
        # ë©€í‹°ì†ŒìŠ¤ ê²€ìƒ‰ ìˆ˜í–‰
        searcher = get_multi_source_searcher()
        papers = searcher.search(
            keywords=keywords,
            max_results=paper_count,
            domain=domain,
            sources=sources_to_search
        )
        
        # ê²€ìƒ‰ ê²°ê³¼ ë¡œê¹…
        observation_content = f"ê²€ìƒ‰ ì™„ë£Œ: {len(papers)}ê°œì˜ ë…¼ë¬¸ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n"
        
        for i, paper in enumerate(papers, 1):
            source_badge = f"[{paper.source}]"
            observation_content += f"\n{i}. {source_badge} {paper.title[:50]}..."
        
        observation_step = ReActStep(
            step_type="observation",
            content=observation_content
        )
        
        logger.info(f"âœ“ ê²€ìƒ‰ ì™„ë£Œ: {len(papers)}ê°œ ë…¼ë¬¸")
        
        return {
            "papers": papers,
            "react_steps": [action_step, observation_step],
            "error_message": None
        }
        
    except Exception as e:
        logger.error(f"ë…¼ë¬¸ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}", exc_info=True)
        
        error_step = ReActStep(
            step_type="observation",
            content=f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        )
        
        return {
            "papers": [],
            "react_steps": [action_step, error_step],
            "error_message": str(e)
        }


# ============================================
# RISS ê²€ìƒ‰ì„ í¬í•¨í•˜ëŠ” ë²„ì „
# ============================================

def search_papers_node_with_riss(state: AgentState) -> dict:
    """
    RISSë¥¼ í¬í•¨í•˜ëŠ” ê²€ìƒ‰ ë…¸ë“œ
    
    ì´ê²ƒì„ ì‚¬ìš©í•˜ë©´ arXivì™€ RISS ëª¨ë‘ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    ë” ë§ì€ ë…¼ë¬¸ì„ ì°¾ì„ ìˆ˜ ìˆì§€ë§Œ, ê²€ìƒ‰ì´ ì•½ê°„ ë” ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤.
    
    config.pyì—ì„œ ì„¤ì •ìœ¼ë¡œ ì „í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """
    
    keywords = state.get("extracted_keywords", [])
    paper_count = state.get("paper_count", 3)
    domain = state.get("question_domain", None)
    
    # RISS í¬í•¨
    sources_to_search = ["arxiv", "riss"]
    
    action_content = f"""ë…¼ë¬¸ ê²€ìƒ‰ì„ ì‹¤í–‰í•©ë‹ˆë‹¤ (ë©€í‹°ì†ŒìŠ¤):
- í‚¤ì›Œë“œ: {', '.join(keywords)}
- ê²€ìƒ‰ ê°œìˆ˜: {paper_count}ê°œ/ì†ŒìŠ¤
- ë„ë©”ì¸: {domain or 'ì „ì²´'}
- ê²€ìƒ‰ ì†ŒìŠ¤: {', '.join(sources_to_search)}
  (arXiv: í•´ì™¸ ë…¼ë¬¸, RISS: í•œêµ­ ë…¼ë¬¸)"""
    
    action_step = ReActStep(
        step_type="action",
        content=action_content
    )
    
    try:
        searcher = get_multi_source_searcher()
        papers = searcher.search(
            keywords=keywords,
            max_results=paper_count,
            domain=domain,
            sources=sources_to_search
        )
        
        # ì¶œì²˜ë³„ ë¶„ë¥˜
        arxiv_count = sum(1 for p in papers if p.source == 'arXiv')
        riss_count = sum(1 for p in papers if p.source == 'RISS')
        
        observation_content = f"""ê²€ìƒ‰ ì™„ë£Œ: {len(papers)}ê°œì˜ ë…¼ë¬¸ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.
- arXiv (í•´ì™¸): {arxiv_count}ê°œ
- RISS (í•œêµ­): {riss_count}ê°œ
"""
        
        for i, paper in enumerate(papers, 1):
            source_badge = f"[{paper.source}]"
            observation_content += f"\n{i}. {source_badge} {paper.title[:50]}..."
        
        observation_step = ReActStep(
            step_type="observation",
            content=observation_content
        )
        
        logger.info(f"âœ“ ë©€í‹°ì†ŒìŠ¤ ê²€ìƒ‰ ì™„ë£Œ: arXiv {arxiv_count}ê°œ + RISS {riss_count}ê°œ")
        
        return {
            "papers": papers,
            "react_steps": [action_step, observation_step],
            "error_message": None
        }
        
    except Exception as e:
        logger.error(f"ë…¼ë¬¸ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        
        error_step = ReActStep(
            step_type="observation",
            content=f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        )
        
        return {
            "papers": [],
            "react_steps": [action_step, error_step],
            "error_message": str(e)
        }


# ============================================
# ì‚¬ìš© ì˜ˆì‹œ
# ============================================

if __name__ == "__main__":
    import logging
    logging.basicConfig(level=logging.INFO)
    
    print("\n" + "="*60)
    print("ğŸ” ë©€í‹°ì†ŒìŠ¤ ê²€ìƒ‰ ì˜ˆì‹œ")
    print("="*60 + "\n")
    
    # í…ŒìŠ¤íŠ¸ ìƒíƒœ ê°ì²´
    test_state = {
        "extracted_keywords": ["attention mechanism", "transformer"],
        "paper_count": 3,
        "question_domain": "computer science"
    }
    
    # 1. arXivë§Œ ê²€ìƒ‰
    print("1ï¸âƒ£ arXivë§Œ ê²€ìƒ‰ (ë¹ ë¦„)")
    print("-" * 60)
    result = search_papers_node(test_state)
    print(f"ê²€ìƒ‰ ì™„ë£Œ: {len(result['papers'])}ê°œ ë…¼ë¬¸")
    for paper in result['papers']:
        print(f"  - {paper.title[:50]}... ({paper.source})")
    
    # 2. arXiv + RISS ê²€ìƒ‰ (RISSê°€ ì„¤ì¹˜ë˜ì–´ ìˆìœ¼ë©´)
    print("\n2ï¸âƒ£ arXiv + RISS í†µí•© ê²€ìƒ‰")
    print("-" * 60)
    
    searcher = get_multi_source_searcher()
    if searcher.riss_client:
        papers = searcher.search(
            keywords=test_state["extracted_keywords"],
            max_results=3,
            sources=["arxiv", "riss"]
        )
        print(f"ê²€ìƒ‰ ì™„ë£Œ: {len(papers)}ê°œ ë…¼ë¬¸")
        for paper in papers:
            print(f"  - {paper.title[:50]}... ({paper.source})")
    else:
        print("RISS í´ë¼ì´ì–¸íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        print("ì„¤ì¹˜: pip install beautifulsoup4 lxml")