"""
ì„ë² ë”© ëª¨ë“ˆ
í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
"""

from typing import List, Union
import numpy as np
from abc import ABC, abstractmethod


class EmbeddingModel(ABC):
    """ì„ë² ë”© ëª¨ë¸ì˜ ì¶”ìƒ ê¸°ë³¸ í´ë˜ìŠ¤"""
    
    @abstractmethod
    def embed(self, text: str) -> List[float]:
        """ë‹¨ì¼ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
        pass
    
    @abstractmethod
    def embed_batch(self, texts: List[str]) -> List[List[float]]:
        """ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ ë°°ì¹˜ë¡œ ì„ë² ë”© ë³€í™˜"""
        pass


class SentenceTransformerEmbedding(EmbeddingModel):
    """Sentence Transformersë¥¼ ì‚¬ìš©í•œ ì„ë² ë”©"""
    
    def __init__(self, model_name: str = "distiluse-base-multilingual-cased-v2"):
        """
        SentenceTransformer ëª¨ë¸ ì´ˆê¸°í™”
        
        Args:
            model_name: ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„
                - "all-MiniLM-L6-v2": ë¹ ë¦„, í•œêµ­ì–´ ì§€ì› ì œí•œì 
                - "distiluse-base-multilingual-cased-v2": ë‹¤êµ­ì–´ ì§€ì› (í•œêµ­ì–´ í¬í•¨)
                - "paraphrase-multilingual-MiniLM-L12-v2": ì˜ë¯¸ë¡ ì ìœ¼ë¡œ ìœ ì‚¬í•œ ë¬¸ì¥ ì¸ì‹
        """
        try:
            from sentence_transformers import SentenceTransformer
            
            print(f"ğŸ”„ '{model_name}' ëª¨ë¸ ë¡œë”© ì¤‘...")
            self.model = SentenceTransformer(model_name)
            self.model_name = model_name
            print(f"âœ“ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            print(f"  - ëª¨ë¸: {model_name}")
            print(f"  - ì°¨ì›: {self.model.get_sentence_embedding_dimension()}")
        
        except ImportError:
            raise ImportError(
                "sentence-transformers íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤. "
                "ì„¤ì¹˜: pip install sentence-transformers"
            )
    
    def embed(self, text: str) -> List[float]:
        """ë‹¨ì¼ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
        if not text or not text.strip():
            # ë¹ˆ ë¬¸ìì—´ì˜ ê²½ìš° ì˜ë²¡í„° ë°˜í™˜
            return [0.0] * self.model.get_sentence_embedding_dimension()
        
        embedding = self.model.encode(text, convert_to_tensor=False)
        return embedding.tolist()
    
    def embed_batch(self, texts: List[str]) -> List[List[float]]:
        """ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ ë°°ì¹˜ë¡œ ì„ë² ë”© ë³€í™˜ (ë” íš¨ìœ¨ì )"""
        embeddings = self.model.encode(texts, convert_to_tensor=False)
        return embeddings.tolist()
    
    def get_embedding_dimension(self) -> int:
        """ì„ë² ë”© ë²¡í„°ì˜ ì°¨ì› ë°˜í™˜"""
        return self.model.get_sentence_embedding_dimension()


class OpenAIEmbedding(EmbeddingModel):
    """OpenAIì˜ ì„ë² ë”© APIë¥¼ ì‚¬ìš©"""
    
    def __init__(self, api_key: str, model: str = "text-embedding-3-small"):
        """
        OpenAI ì„ë² ë”© ì´ˆê¸°í™”
        
        Args:
            api_key: OpenAI API í‚¤
            model: ì‚¬ìš©í•  ëª¨ë¸
                - "text-embedding-3-small": 1536ì°¨ì›, ì €ë ´
                - "text-embedding-3-large": 3072ì°¨ì›, ê³ ì„±ëŠ¥
        """
        try:
            from openai import OpenAI
            
            self.client = OpenAI(api_key=api_key)
            self.model = model
            print(f"âœ“ OpenAI ì„ë² ë”© ì´ˆê¸°í™” ì™„ë£Œ (ëª¨ë¸: {model})")
        
        except ImportError:
            raise ImportError(
                "openai íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤. "
                "ì„¤ì¹˜: pip install openai"
            )
    
    def embed(self, text: str) -> List[float]:
        """OpenAI APIë¥¼ ì´ìš©í•œ ë‹¨ì¼ ì„ë² ë”©"""
        response = self.client.embeddings.create(
            input=text,
            model=self.model
        )
        return response.data[0].embedding
    
    def embed_batch(self, texts: List[str]) -> List[List[float]]:
        """OpenAI APIë¥¼ ì´ìš©í•œ ë°°ì¹˜ ì„ë² ë”©"""
        response = self.client.embeddings.create(
            input=texts,
            model=self.model
        )
        # ì‘ë‹µ ìˆœì„œê°€ ì…ë ¥ ìˆœì„œì™€ ê°™ìŒì„ ë³´ì¥
        return [item.embedding for item in response.data]


class CachedEmbedding(EmbeddingModel):
    """ì„ë² ë”©ì„ ìºì‹±í•˜ì—¬ ì„±ëŠ¥ì„ ê°œì„ í•˜ëŠ” ë˜í¼"""
    
    def __init__(self, embedding_model: EmbeddingModel):
        """
        ìºì‹± ë˜í¼ ì´ˆê¸°í™”
        
        Args:
            embedding_model: ì‹¤ì œ ì„ë² ë”©ì„ ìˆ˜í–‰í•  ëª¨ë¸
        """
        self.model = embedding_model
        self.cache = {}
        print("âœ“ ìºì‹± ì„ë² ë”© í™œì„±í™”")
    
    def embed(self, text: str) -> List[float]:
        """ìºì‹œë¥¼ ì´ìš©í•œ ì„ë² ë”© (ë™ì¼ í…ìŠ¤íŠ¸ëŠ” ì¬ê³„ì‚° ì•ˆí•¨)"""
        # í…ìŠ¤íŠ¸ë¥¼ ì •ê·œí™”í•˜ì—¬ ìºì‹œ í‚¤ë¡œ ì‚¬ìš©
        cache_key = text.strip().lower()
        
        if cache_key not in self.cache:
            self.cache[cache_key] = self.model.embed(text)
        
        return self.cache[cache_key]
    
    def embed_batch(self, texts: List[str]) -> List[List[float]]:
        """ë°°ì¹˜ ì„ë² ë”© (ìºì‹œ í™œìš©)"""
        embeddings = []
        texts_to_embed = []
        indices_to_embed = []
        
        # ìºì‹œë˜ì§€ ì•Šì€ í…ìŠ¤íŠ¸ë§Œ í•„í„°ë§
        for idx, text in enumerate(texts):
            cache_key = text.strip().lower()
            
            if cache_key in self.cache:
                embeddings.append(self.cache[cache_key])
            else:
                texts_to_embed.append(text)
                indices_to_embed.append(idx)
                embeddings.append(None)
        
        # ìºì‹œë˜ì§€ ì•Šì€ í…ìŠ¤íŠ¸ë“¤ì„ ë°°ì¹˜ë¡œ ì„ë² ë”©
        if texts_to_embed:
            new_embeddings = self.model.embed_batch(texts_to_embed)
            
            for idx, embedding in zip(indices_to_embed, new_embeddings):
                embeddings[idx] = embedding
                cache_key = texts[idx].strip().lower()
                self.cache[cache_key] = embedding
        
        return embeddings
    
    def get_cache_stats(self) -> dict:
        """ìºì‹œ í†µê³„"""
        return {
            "cached_items": len(self.cache),
            "model": str(self.model)
        }


# ì‚¬ìš© ì˜ˆì‹œ í•¨ìˆ˜
def example_usage():
    """ì„ë² ë”© ëª¨ë“ˆ ì‚¬ìš© ì˜ˆì‹œ"""
    
    # 1. Sentence Transformers ì‚¬ìš© (ê¶Œì¥)
    print("="*50)
    print("1. Sentence Transformers ì„ë² ë”©")
    print("="*50)
    
    embedding_model = SentenceTransformerEmbedding(
        model_name="distiluse-base-multilingual-cased-v2"
    )
    
    # 2. ë‹¨ì¼ í…ìŠ¤íŠ¸ ì„ë² ë”©
    text = "This is a sample text about machine learning"
    embedding = embedding_model.embed(text)
    print(f"\nğŸ“ í…ìŠ¤íŠ¸: {text}")
    print(f"ğŸ“Š ì„ë² ë”© ì°¨ì›: {len(embedding)}")
    print(f"ğŸ“Š ì„ë² ë”© (ì²˜ìŒ 5ê°œ): {embedding[:5]}")
    
    # 3. ë°°ì¹˜ ì„ë² ë”© (ì—¬ëŸ¬ ë¬¸ì„œ)
    print("\n" + "="*50)
    print("2. ë°°ì¹˜ ì„ë² ë”©")
    print("="*50)
    
    texts = [
        "Machine learning is a subset of artificial intelligence",
        "Natural language processing helps computers understand text",
        "Deep learning uses neural networks with multiple layers"
    ]
    
    embeddings = embedding_model.embed_batch(texts)
    print(f"\nâœ“ {len(texts)}ê°œ í…ìŠ¤íŠ¸ ì„ë² ë”© ì™„ë£Œ")
    print(f"ğŸ“Š ê° ì„ë² ë”© ì°¨ì›: {len(embeddings[0])}")
    
    # 4. ìºì‹± í™œìš© (ë°˜ë³µë˜ëŠ” í…ìŠ¤íŠ¸ê°€ ìˆì„ ë•Œ íš¨ìœ¨ì )
    print("\n" + "="*50)
    print("3. ìºì‹± ì„ë² ë”© (ì„±ëŠ¥ ê°œì„ )")
    print("="*50)
    
    cached_embedding = CachedEmbedding(embedding_model)
    
    # ê°™ì€ í…ìŠ¤íŠ¸ë¥¼ ì—¬ëŸ¬ ë²ˆ ì„ë² ë”©
    test_text = "Artificial intelligence and machine learning"
    
    import time
    
    start = time.time()
    emb1 = cached_embedding.embed(test_text)
    time1 = time.time() - start
    
    start = time.time()
    emb2 = cached_embedding.embed(test_text)  # ìºì‹œì—ì„œ ê°€ì ¸ì˜´
    time2 = time.time() - start
    
    print(f"\nì²« ë²ˆì§¸ ì„ë² ë”©: {time1*1000:.2f}ms")
    print(f"ë‘ ë²ˆì§¸ ì„ë² ë”© (ìºì‹œ): {time2*1000:.2f}ms")
    print(f"ì†ë„ í–¥ìƒ: {time1/time2:.1f}ë°°")
    
    # ìºì‹œ í†µê³„
    stats = cached_embedding.get_cache_stats()
    print(f"\nğŸ“Š ìºì‹œ í†µê³„: {stats}")


if __name__ == "__main__":
    example_usage()