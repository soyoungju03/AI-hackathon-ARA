# app/graph/workflow.py
# -*- coding: utf-8 -*-
"""
ì™„ì „íˆ ìˆ˜ì •ëœ LangGraph ì›Œí¬í”Œë¡œìš° (ì¬ë¶„ì„ ëª¨ë“œ ì§€ì› - ë‹¨ìˆœí™” ë²„ì „)
================================================================================

í•µì‹¬ ìˆ˜ì •ì‚¬í•­:
- "ë‹¤ì‹œ" ì„ íƒ ì‹œ ì¬ë¶„ì„ í›„ ë‹¤ì‹œ í‚¤ì›Œë“œ í™•ì¸ì„ ê±°ì¹¨
- ë¬´í•œ ë£¨í”„ ë°©ì§€: ì¬ë¶„ì„ì€ ë˜ì§€ë§Œ í•­ìƒ ì‚¬ìš©ì í™•ì¸ í•„ìš”
- ì‚¬ìš©ì ê²½í—˜ ê°œì„ : ìƒˆë¡œìš´ í‚¤ì›Œë“œë¥¼ í•­ìƒ í™•ì¸í•  ìˆ˜ ìˆìŒ

íŒŒì´í”„ë¼ì¸ íë¦„:
ì‚¬ìš©ì ì§ˆë¬¸ â†’ í‚¤ì›Œë“œ ì¶”ì¶œ â†’ [ì‚¬ìš©ì í™•ì¸] â†’
["ë‹¤ì‹œ" ì„ íƒ ì‹œ â†’ ì¬ë¶„ì„ â†’ ë‹¤ì‹œ í‚¤ì›Œë“œ í™•ì¸] â†’
["í™•ì¸" ì„ íƒ ì‹œ â†’ ë…¼ë¬¸ ìˆ˜ ì„ íƒ] â†’ arXiv ê²€ìƒ‰ â†’ PDF ì²˜ë¦¬ â†’ ì˜ë¯¸ ê²€ìƒ‰ â†’ ë‹µë³€ ìƒì„±
"""

from typing import Literal
import logging
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver

from app.graph.state import AgentState, create_initial_state, ReActStep
from app.graph.nodes import (
    receive_question_node,
    analyze_question_node,
    request_keyword_confirmation_node,
    process_keyword_confirmation_response_node,
    request_paper_count_node,
    process_paper_count_response_node,
    search_papers_node,
    evaluate_relevance_node,
    summarize_papers_node,
    generate_response_node
)

logger = logging.getLogger(__name__)


# ============================================
# ì›Œí¬í”Œë¡œìš° ë¹Œë“œ (ë‹¨ìˆœí™”ëœ ë²„ì „)
# ============================================

def build_research_workflow() -> StateGraph:
    """
    ì¬ë¶„ì„ ëª¨ë“œë¥¼ ì§€ì›í•˜ëŠ” ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.
    
    í•µì‹¬ ë³€ê²½ì‚¬í•­:
    1. ì¬ë¶„ì„ í›„ì—ë„ í•­ìƒ í‚¤ì›Œë“œ í™•ì¸ì„ ê±°ì¹¨
    2. route_after_analyze í•¨ìˆ˜ ë‹¨ìˆœí™”
    3. ì‚¬ìš©ìëŠ” í•­ìƒ ìƒˆë¡œìš´ í‚¤ì›Œë“œë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŒ
    
    ì›Œí¬í”Œë¡œìš° êµ¬ì¡°:
    
    START
      â†“
    receive_question
      â†“
    analyze_question
      â†“
    request_keyword_confirmation (í•­ìƒ ì´ ë‹¨ê³„ë¥¼ ê±°ì¹¨)
      â†“
    [INTERRUPT 1] 
      â†“
    process_keyword_confirmation_response
      â†“
    [ì¡°ê±´ë¶€ ë¶„ê¸°]
    â”œâ”€ analyze_question (ì‚¬ìš©ìê°€ 'ë‹¤ì‹œ' ì„ íƒ â†’ ì¬ë¶„ì„ â†’ ë‹¤ì‹œ í™•ì¸)
    â””â”€ request_paper_count (ì‚¬ìš©ìê°€ 'í™•ì¸' ì„ íƒ)
      â†“
    [INTERRUPT 2] 
      â†“
    process_paper_count_response
      â†“
    search_papers (â†’ PDF ì„ë² ë”© íŒŒì´í”„ë¼ì¸)
      â†“
    [ì¡°ê±´ë¶€ ë¶„ê¸°]
    â”œâ”€ generate_response (ì˜¤ë¥˜ ë°œìƒ ì‹œ)
    â””â”€ evaluate_relevance (â†’ ChromaDB ì˜ë¯¸ ê²€ìƒ‰)
      â†“
    summarize_papers
      â†“
    generate_response
      â†“
    END
    """
    
    workflow = StateGraph(AgentState)
    
    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("receive_question", receive_question_node)
    workflow.add_node("analyze_question", analyze_question_node)
    workflow.add_node("request_keyword_confirmation", request_keyword_confirmation_node)
    workflow.add_node("process_keyword_confirmation_response", process_keyword_confirmation_response_node)
    workflow.add_node("request_paper_count", request_paper_count_node)
    workflow.add_node("process_paper_count_response", process_paper_count_response_node)
    workflow.add_node("search_papers", search_papers_node)
    workflow.add_node("evaluate_relevance", evaluate_relevance_node)
    workflow.add_node("summarize_papers", summarize_papers_node)
    workflow.add_node("generate_response", generate_response_node)
    
    # ì—£ì§€ ì •ì˜
    workflow.set_entry_point("receive_question")
    
    # ì´ˆê¸° ì²˜ë¦¬ íë¦„
    workflow.add_edge("receive_question", "analyze_question")
    
    # ğŸ”‘ í•µì‹¬ ë‹¨ìˆœí™”: í•­ìƒ í‚¤ì›Œë“œ í™•ì¸ìœ¼ë¡œ ì´ë™
    workflow.add_edge("analyze_question", "request_keyword_confirmation")
    
    # í‚¤ì›Œë“œ í™•ì¸ íë¦„
    workflow.add_edge("request_keyword_confirmation", "process_keyword_confirmation_response")
    
    # í‚¤ì›Œë“œ í™•ì¸ í›„ ì¡°ê±´ë¶€ ë¶„ê¸°
    def route_after_keyword_confirmation(state: AgentState) -> Literal["analyze_question", "request_paper_count"]:
        """
        í‚¤ì›Œë“œ í™•ì¸ í›„ ê²½ë¡œë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
        
        ì‚¬ìš©ìê°€ "ë‹¤ì‹œ"ë¥¼ ì…ë ¥í–ˆë‹¤ë©´ keyword_confirmation_responseê°€ "retry"ë¡œ
        ì„¤ì •ë˜ì–´ ìˆì„ ê²ƒì´ê³ , ì´ ê²½ìš° analyze_question ë…¸ë“œë¡œ ëŒì•„ê°‘ë‹ˆë‹¤.
        ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ request_paper_count ë…¸ë“œë¡œ ì§„í–‰í•©ë‹ˆë‹¤.
        """
        keyword_response = state.get("keyword_confirmation_response")
        
        logger.info("=" * 60)
        logger.info("[ROUTE_AFTER_KEYWORD_CONFIRMATION] ê²½ë¡œ ê²°ì •")
        logger.info(f"  keyword_confirmation_response: {keyword_response}")
        logger.info("=" * 60)
        
        if keyword_response == "retry":
            logger.info("  â†’ ê²½ë¡œ: analyze_question (ì§ˆë¬¸ ì¬ë¶„ì„)")
            return "analyze_question"
        else:
            logger.info("  â†’ ê²½ë¡œ: request_paper_count (ë…¼ë¬¸ ìˆ˜ ì„ íƒ)")
            return "request_paper_count"
    
    workflow.add_conditional_edges(
        "process_keyword_confirmation_response",
        route_after_keyword_confirmation,
        {
            "analyze_question": "analyze_question",
            "request_paper_count": "request_paper_count"
        }
    )
    
    # ë…¼ë¬¸ ìˆ˜ ì„ íƒ íë¦„
    workflow.add_edge("request_paper_count", "process_paper_count_response")
    workflow.add_edge("process_paper_count_response", "search_papers")
    
    # ê²€ìƒ‰ ê²°ê³¼ì— ë”°ë¥¸ ì¡°ê±´ë¶€ ë¶„ê¸°
    def check_search_results(state: AgentState) -> Literal["evaluate_relevance", "generate_response"]:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™•ì¸í•˜ê³  ë‹¤ìŒ ê²½ë¡œë¥¼ ê²°ì •í•©ë‹ˆë‹¤."""
        if state.get("error_message"):
            logger.info("[CHECK_SEARCH_RESULTS] ê²€ìƒ‰ ì‹¤íŒ¨ â†’ generate_response")
            return "generate_response"
        logger.info("[CHECK_SEARCH_RESULTS] ê²€ìƒ‰ ì„±ê³µ â†’ evaluate_relevance (ì˜ë¯¸ ê¸°ë°˜ í‰ê°€)")
        return "evaluate_relevance"
    
    workflow.add_conditional_edges(
        "search_papers",
        check_search_results,
        {
            "evaluate_relevance": "evaluate_relevance",
            "generate_response": "generate_response"
        }
    )
    
    # ìµœì¢… ì²˜ë¦¬ íë¦„
    workflow.add_edge("evaluate_relevance", "summarize_papers")
    workflow.add_edge("summarize_papers", "generate_response")
    workflow.add_edge("generate_response", END)
    
    return workflow


# ============================================
# ì—ì´ì „íŠ¸ ìƒì„± ë° ì‹¤í–‰
# ============================================

def create_research_agent(checkpointer=None):
    """
    ì¬ë¶„ì„ ëª¨ë“œë¥¼ ì§€ì›í•˜ëŠ” ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    checkpointerëŠ” ì›Œí¬í”Œë¡œìš°ì˜ ìƒíƒœë¥¼ ì €ì¥í•˜ê³  ë³µì›í•˜ì—¬
    Human-in-the-Loopì—ì„œ ë©ˆì·„ë‹¤ê°€ ë‚˜ì¤‘ì— ê³„ì† ì§„í–‰í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.
    """
    
    workflow = build_research_workflow()
    
    if checkpointer is None:
        checkpointer = MemorySaver()
    
    compiled = workflow.compile(
        checkpointer=checkpointer,
        interrupt_before=[
            "process_keyword_confirmation_response",
            "process_paper_count_response"
        ]
    )
    
    logger.info("âœ“ ì›Œí¬í”Œë¡œìš° ì»´íŒŒì¼ ì™„ë£Œ (ì¬ë¶„ì„ ëª¨ë“œ ì§€ì› - ë‹¨ìˆœí™” ë²„ì „)")
    return compiled


# ============================================
# ResearchAssistant í´ë˜ìŠ¤
# ============================================

class ResearchAssistant:
    """
    ì¬ë¶„ì„ ëª¨ë“œë¥¼ ì§€ì›í•˜ëŠ” ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
    
    ì „ì²´ ì²˜ë¦¬ íë¦„:
    1. ì‚¬ìš©ì ì§ˆë¬¸ ìˆ˜ì‹ 
    2. í‚¤ì›Œë“œ ì¶”ì¶œ ë° ì‚¬ìš©ì í™•ì¸
    3. "ë‹¤ì‹œ" ì„ íƒ ì‹œ: ì¬ë¶„ì„ â†’ ë‹¤ì‹œ í‚¤ì›Œë“œ í™•ì¸
    4. "í™•ì¸" ì„ íƒ ì‹œ: ë…¼ë¬¸ ìˆ˜ ì„ íƒ
    5. arXiv ê²€ìƒ‰ ë° PDF ì²˜ë¦¬
    6. ì˜ë¯¸ ê¸°ë°˜ ì²­í¬ ê²€ìƒ‰
    7. ìš”ì•½ ë° ë‹µë³€ ìƒì„±
    """
    
    def __init__(self):
        """ì–´ì‹œìŠ¤í„´íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        self.checkpointer = MemorySaver()
        self.agent = create_research_agent(self.checkpointer)
        self.current_thread_id = None
        self.interrupt_count = 0
    
    def run(
        self,
        question: str,
        paper_count: int = 3,
        session_id: str = "default"
    ) -> str:
        """ìë™ ì‹¤í–‰ ëª¨ë“œ: Human-in-the-Loop ì—†ì´ ì „ì²´ ì›Œí¬í”Œë¡œìš°ë¥¼ ìë™ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        
        import uuid
        
        initial_state = create_initial_state(question, session_id)
        initial_state["paper_count"] = paper_count
        initial_state["keyword_confirmation_response"] = "confirmed"
        initial_state["waiting_for_user"] = False
        
        thread_id = str(uuid.uuid4())
        config = {"configurable": {"thread_id": thread_id}}
        
        try:
            logger.info(f"[RUN MODE] ìë™ ì‹¤í–‰ ì‹œì‘: {question[:50]}...")
            
            final_state = self.agent.invoke(initial_state, config)
            
            logger.info("[RUN MODE] âœ“ ìë™ ì‹¤í–‰ ì™„ë£Œ")
            return final_state.get("final_response", "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        except Exception as e:
            logger.error(f"[RUN MODE] ì˜¤ë¥˜: {str(e)}", exc_info=True)
            return f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def start(self, question: str, session_id: str = "default") -> dict:
        """ëŒ€í™”í˜• ëª¨ë“œ: ì²« ë²ˆì§¸ Interrupt (í‚¤ì›Œë“œ í™•ì¸)ì—ì„œ ë©ˆì¶¥ë‹ˆë‹¤."""
        
        import uuid
        
        logger.info(f"[START MODE] ì‹œì‘: {question[:50]}...")
        
        initial_state = create_initial_state(question, session_id)
        
        self.current_thread_id = str(uuid.uuid4())
        self.interrupt_count = 0
        config = {"configurable": {"thread_id": self.current_thread_id}}
        
        try:
            logger.info("[START MODE] ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘...")
            
            for event in self.agent.stream(initial_state, config):
                pass
            
            state_snapshot = self.agent.get_state(config)
            current_values = state_snapshot.values
            
            self.interrupt_count = 1
            logger.info("[START MODE] âœ“ ì²« ë²ˆì§¸ Interrupt ë„ë‹¬")
            
            if current_values.get("interrupt_data"):
                interrupt_data = current_values["interrupt_data"]
                
                return {
                    "status": "waiting_for_input",
                    "interrupt_stage": 1,
                    "message": interrupt_data.message,
                    "options": interrupt_data.options,
                    "keywords": current_values.get("extracted_keywords", []),
                    "thread_id": self.current_thread_id
                }
            else:
                return {
                    "status": "completed",
                    "response": current_values.get("final_response", ""),
                    "thread_id": self.current_thread_id
                }
        
        except Exception as e:
            logger.error(f"[START MODE] ì˜¤ë¥˜: {str(e)}", exc_info=True)
            return {
                "status": "error",
                "message": str(e),
                "thread_id": self.current_thread_id
            }
    
    def continue_with_response(self, user_response: str) -> dict:
        """ì‚¬ìš©ì ì‘ë‹µì„ ë°›ì•„ ì›Œí¬í”Œë¡œìš°ë¥¼ ê³„ì† ì‹¤í–‰í•©ë‹ˆë‹¤."""
        
        logger.info(f"[CONTINUE MODE] ì‚¬ìš©ì ì‘ë‹µ (Stage {self.interrupt_count}): {user_response}")
        
        if not self.current_thread_id:
            logger.error("[CONTINUE MODE] thread_id ì—†ìŒ")
            return {
                "status": "error",
                "message": "ë¨¼ì € start()ë¥¼ í˜¸ì¶œí•´ì£¼ì„¸ìš”."
            }
        
        config = {"configurable": {"thread_id": self.current_thread_id}}
        
        try:
            if self.interrupt_count == 1:
                logger.info("[CONTINUE MODE] Stage 1: í‚¤ì›Œë“œ í™•ì¸ ì‘ë‹µ")
                
                normalized_response = user_response.strip().lower()
                keyword_response = "retry" if normalized_response in ["ë‹¤ì‹œ", "retry", "ìˆ˜ì •"] else "confirmed"
                
                logger.info(f"  â†’ ì •ê·œí™”ëœ ì‘ë‹µ: {keyword_response}")
                
                self.agent.update_state(
                    config,
                    {
                        "user_response": user_response,
                        "keyword_confirmation_response": keyword_response,
                        "waiting_for_user": False
                    }
                )
            
            elif self.interrupt_count == 2:
                logger.info("[CONTINUE MODE] Stage 2: ë…¼ë¬¸ ìˆ˜ ì„ íƒ")
                
                self.agent.update_state(
                    config,
                    {
                        "user_response": user_response,
                        "waiting_for_user": False
                    }
                )
            
            logger.info("[CONTINUE MODE] ì›Œí¬í”Œë¡œìš° ê³„ì† ì‹¤í–‰ ì¤‘...")
            
            for event in self.agent.stream(None, config):
                pass
            
            state_snapshot = self.agent.get_state(config)
            current_values = state_snapshot.values
            
            logger.info("[CONTINUE MODE] ì‹¤í–‰ ì™„ë£Œ, ìƒíƒœ í™•ì¸")
            
            if current_values.get("is_complete"):
                logger.info("[CONTINUE MODE] âœ“ ì›Œí¬í”Œë¡œìš° ì™„ë£Œ")
                return {
                    "status": "completed",
                    "interrupt_stage": self.interrupt_count,
                    "response": current_values.get("final_response", ""),
                    "chunks": current_values.get("relevant_chunks", []),
                    "thread_id": self.current_thread_id
                }
            
            if current_values.get("interrupt_data"):
                # ğŸ”‘ ìˆ˜ì •: "ë‹¤ì‹œ" ì„ íƒ ì‹œ interrupt_countë¥¼ ì¦ê°€ì‹œí‚¤ì§€ ì•ŠìŒ
                # ì¬ë¶„ì„ í›„ ë‹¤ì‹œ í‚¤ì›Œë“œ í™•ì¸(Stage 1)ìœ¼ë¡œ ëŒì•„ê°€ë¯€ë¡œ
                interrupt_data = current_values["interrupt_data"]
                
                # í˜„ì¬ ì–´ë–¤ interruptì¸ì§€ í™•ì¸
                if interrupt_data.interrupt_type == "confirm_keywords":
                    # í‚¤ì›Œë“œ í™•ì¸ ë‹¨ê³„ (ì¬ë¶„ì„ í›„ ëŒì•„ì˜¨ ê²½ìš°)
                    self.interrupt_count = 1
                    logger.info(f"[CONTINUE MODE] â†’ í‚¤ì›Œë“œ ì¬í™•ì¸: Stage {self.interrupt_count}")
                elif interrupt_data.interrupt_type == "select_paper_count":
                    # ë…¼ë¬¸ ìˆ˜ ì„ íƒ ë‹¨ê³„
                    self.interrupt_count = 2
                    logger.info(f"[CONTINUE MODE] â†’ ë…¼ë¬¸ ìˆ˜ ì„ íƒ: Stage {self.interrupt_count}")
                
                return {
                    "status": "waiting_for_input",
                    "interrupt_stage": self.interrupt_count,
                    "message": interrupt_data.message,
                    "options": interrupt_data.options,
                    "keywords": current_values.get("extracted_keywords", []),  # ğŸ”‘ ì¶”ê°€: ìƒˆ í‚¤ì›Œë“œ ì „ë‹¬
                    "thread_id": self.current_thread_id
                }
            
            logger.warning("[CONTINUE MODE] ì˜ˆìƒ ì™¸ì˜ ìƒíƒœ")
            return {
                "status": "unknown",
                "message": "ì›Œí¬í”Œë¡œìš° ìƒíƒœë¥¼ íŒŒì•…í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "thread_id": self.current_thread_id
            }
        
        except Exception as e:
            logger.error(f"[CONTINUE MODE] ì˜¤ë¥˜: {str(e)}", exc_info=True)
            return {
                "status": "error",
                "message": str(e),
                "thread_id": self.current_thread_id
            }


# ============================================
# ì‹±ê¸€í†¤ íŒ¨í„´
# ============================================

_default_assistant = None

def get_assistant() -> ResearchAssistant:
    """ì „ì—­ ì–´ì‹œìŠ¤í„´íŠ¸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    global _default_assistant
    if _default_assistant is None:
        _default_assistant = ResearchAssistant()
    return _default_assistant