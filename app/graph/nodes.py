# -*- coding: utf-8 -*-
"""
LangGraph ë…¸ë“œ ì •ì˜
===================

ì´ íŒŒì¼ì€ LangGraph ì›Œí¬í”Œë¡œìš°ì˜ ê° ë…¸ë“œ(Node)ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.

ë…¸ë“œ(Node)ë€?
-------------
LangGraphì—ì„œ ë…¸ë“œëŠ” ì›Œí¬í”Œë¡œìš°ì˜ ê° ë‹¨ê³„ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
ê° ë…¸ë“œëŠ” ìƒíƒœ(State)ë¥¼ ì…ë ¥ë°›ì•„ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê³ ,
ìˆ˜ì •ëœ ìƒíƒœë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

ReAct íŒ¨í„´ ì ìš©
---------------
ê° ë…¸ë“œëŠ” ReAct íŒ¨í„´ì˜ ì¼ë¶€ë¥¼ ë‹´ë‹¹í•©ë‹ˆë‹¤:
- Thought (ìƒê°): í˜„ì¬ ìƒí™© ë¶„ì„
- Action (í–‰ë™): ë„êµ¬ ì‹¤í–‰ ë“±ì˜ í–‰ë™ ìˆ˜í–‰
- Observation (ê´€ì°°): í–‰ë™ ê²°ê³¼ ê´€ì°° ë° ê¸°ë¡

Human-in-the-Loop
-----------------
íŠ¹ì • ë…¸ë“œëŠ” Interruptë¥¼ ë°œìƒì‹œì¼œ ì‚¬ìš©ì ì…ë ¥ì„ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.
ì´ ê¸°ëŠ¥ì€ LangGraphì˜ `interrupt_before` ë˜ëŠ” `interrupt_after` ì˜µì…˜ìœ¼ë¡œ êµ¬í˜„ë©ë‹ˆë‹¤.
"""

import os
from typing import Literal
from datetime import datetime

# LangChain/LangGraph ì„í¬íŠ¸
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
from app.graph.state import (
    AgentState, 
    Paper, 
    ReActStep, 
    InterruptData,
    add_react_step
)
from app.tools.paper_search.arxiv_tool import search_arxiv
from app.config import get_settings

# ì„¤ì • ë¡œë“œ
settings = get_settings()


def get_llm(model: str = None):
    """
    LLM ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    ì´ í•¨ìˆ˜ëŠ” ì„¤ì •ëœ API í‚¤ì™€ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ 
    ChatOpenAI ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    return ChatOpenAI(
        model=model or settings.default_model,
        api_key=settings.openai_api_key,
        temperature=0.3  # ì¼ê´€ëœ ê²°ê³¼ë¥¼ ìœ„í•´ ë‚®ì€ temperature
    )


# ============================================
# ë…¸ë“œ 1: ì§ˆë¬¸ ìˆ˜ì‹  (receive_question)
# ============================================

def receive_question_node(state: AgentState) -> dict:
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì„ ìˆ˜ì‹ í•˜ê³  ì´ˆê¸° ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.
    
    ì´ ë…¸ë“œëŠ” ì›Œí¬í”Œë¡œìš°ì˜ ì‹œì‘ì ì…ë‹ˆë‹¤.
    ì‚¬ìš©ì ì§ˆë¬¸ì„ ë°›ì•„ì„œ ReActì˜ ì²« ë²ˆì§¸ Thoughtë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤.
    
    Args:
        state: í˜„ì¬ ì›Œí¬í”Œë¡œìš° ìƒíƒœ
    
    Returns:
        dict: ìƒíƒœ ì—…ë°ì´íŠ¸ ë”•ì…”ë„ˆë¦¬
    """
    user_question = state["user_question"]
    
    # ReAct Thought ê¸°ë¡: ì§ˆë¬¸ì„ ë°›ì•˜ìŒì„ ì¸ì‹
    thought_content = f"""
ì‚¬ìš©ì ì§ˆë¬¸ì„ ìˆ˜ì‹ í–ˆìŠµë‹ˆë‹¤: "{user_question}"
ì´ì œ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ í•µì‹¬ í‚¤ì›Œë“œì™€ ì˜ë„ë¥¼ íŒŒì•…í•´ì•¼ í•©ë‹ˆë‹¤.
    """.strip()
    
    new_step = ReActStep(
        step_type="thought",
        content=thought_content
    )
    
    return {
        "react_steps": [new_step]
    }


# ============================================
# ë…¸ë“œ 2: ì§ˆë¬¸ ë¶„ì„ (analyze_question)
# ============================================

QUESTION_ANALYSIS_PROMPT = """
ë‹¹ì‹ ì€ í•™ìˆ  ì—°êµ¬ ì§ˆë¬¸ì„ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

## ì‚¬ìš©ì ì§ˆë¬¸
{question}

## ë¶„ì„í•´ì•¼ í•  í•­ëª©

1. **í•µì‹¬ í‚¤ì›Œë“œ**: ë…¼ë¬¸ ê²€ìƒ‰ì— ì‚¬ìš©í•  í•µì‹¬ ê¸°ìˆ  í‚¤ì›Œë“œ 2-5ê°œ
   - ì˜ì–´ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš” (arXivëŠ” ì˜ì–´ ë…¼ë¬¸ì´ ëŒ€ë¶€ë¶„ì…ë‹ˆë‹¤)
   - êµ¬ì²´ì ì´ê³  ê²€ìƒ‰ íš¨ê³¼ê°€ ì¢‹ì€ í‚¤ì›Œë“œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”

2. **ì§ˆë¬¸ ì˜ë„**: ì‚¬ìš©ìê°€ ì•Œê³  ì‹¶ì–´í•˜ëŠ” ê²ƒì´ ë¬´ì—‡ì¸ì§€
   - "ìµœì‹  ì—°êµ¬ ë™í–¥" / "íŠ¹ì • ê¸°ìˆ  ì„¤ëª…" / "ë¹„êµ ë¶„ì„" / "ì‘ìš© ì‚¬ë¡€" ë“±

3. **ì—°êµ¬ ë„ë©”ì¸**: ì–´ë–¤ í•™ë¬¸ ë¶„ì•¼ì— í•´ë‹¹í•˜ëŠ”ì§€
   - "computer science" / "physics" / "mathematics" / "biology" ë“±

## ì‘ë‹µ í˜•ì‹ (ë°˜ë“œì‹œ ì´ í˜•ì‹ì„ ë”°ë¼ì£¼ì„¸ìš”)
KEYWORDS: keyword1, keyword2, keyword3
INTENT: ì§ˆë¬¸ ì˜ë„ ì„¤ëª…
DOMAIN: ì—°êµ¬ ë„ë©”ì¸
"""


import logging

logger = logging.getLogger(__name__)

def analyze_question_node(state: AgentState) -> dict:
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ í‚¤ì›Œë“œ, ì˜ë„, ë„ë©”ì¸ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    user_question = state["user_question"]
    
    # ë¡œê¹…: ë¶„ì„ ì‹œì‘
    logger.info(f"ğŸ” ì§ˆë¬¸ ë¶„ì„ ì‹œì‘: {user_question}")
    
    # LLM í˜¸ì¶œ
    llm = get_llm(settings.light_model)
    prompt = QUESTION_ANALYSIS_PROMPT.format(question=user_question)
    
    # ë¡œê¹…: LLM í˜¸ì¶œ ì „
    logger.info("ğŸ“¡ LLMì— ìš”ì²­ ì „ì†¡ ì¤‘...")
    
    response = llm.invoke([
        SystemMessage(content="ë‹¹ì‹ ì€ í•™ìˆ  ì—°êµ¬ ì§ˆë¬¸ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."),
        HumanMessage(content=prompt)
    ])
    
    # ë¡œê¹…: LLM ì‘ë‹µ ìˆ˜ì‹ 
    logger.info(f"âœ… LLM ì‘ë‹µ ìˆ˜ì‹ : {response.content[:100]}...")
    
    # ì‘ë‹µ íŒŒì‹±
    response_text = response.content
    
    # í‚¤ì›Œë“œ ì¶”ì¶œ
    keywords = []
    intent = ""
    domain = ""
    
    for line in response_text.strip().split('\n'):
        line = line.strip()
        if line.startswith("KEYWORDS:"):
            keywords_str = line.replace("KEYWORDS:", "").strip()
            keywords = [k.strip() for k in keywords_str.split(",") if k.strip()]
        elif line.startswith("INTENT:"):
            intent = line.replace("INTENT:", "").strip()
        elif line.startswith("DOMAIN:"):
            domain = line.replace("DOMAIN:", "").strip()
    
    # ë¡œê¹…: íŒŒì‹± ì™„ë£Œ
    logger.info(f"ğŸ”‘ ì¶”ì¶œëœ í‚¤ì›Œë“œ: {keywords}")
    logger.info(f"ğŸ¯ ì§ˆë¬¸ ì˜ë„: {intent}")
    logger.info(f"ğŸ“š ì—°êµ¬ ë„ë©”ì¸: {domain}")
    
    # ReAct Observation ê¸°ë¡
    observation_content = f"""
ì§ˆë¬¸ ë¶„ì„ ì™„ë£Œ:
- ì¶”ì¶œëœ í‚¤ì›Œë“œ: {keywords}
- ì§ˆë¬¸ ì˜ë„: {intent}
- ì—°êµ¬ ë„ë©”ì¸: {domain}
    """.strip()
    
    new_step = ReActStep(
        step_type="observation",
        content=observation_content
    )
    
    return {
        "extracted_keywords": keywords,
        "question_intent": intent,
        "question_domain": domain,
        "react_steps": [new_step]
    }


# ============================================
# ë…¸ë“œ 3: ì‚¬ìš©ì í™•ì¸ ìš”ì²­ (request_user_confirmation)
# Human-in-the-Loop Interrupt ë°œìƒ
# ============================================

def request_user_confirmation_node(state: AgentState) -> dict:
    """
    ì‚¬ìš©ìì—ê²Œ í‚¤ì›Œë“œì™€ ê²€ìƒ‰ ì„¤ì •ì„ í™•ì¸ë°›ìŠµë‹ˆë‹¤.
    
    ì´ ë…¸ë“œëŠ” Human-in-the-Loopì˜ í•µì‹¬ì…ë‹ˆë‹¤.
    Interruptë¥¼ ë°œìƒì‹œì¼œ ì›Œí¬í”Œë¡œìš°ë¥¼ ì¼ì‹œ ì¤‘ì§€í•˜ê³ ,
    ì‚¬ìš©ìì˜ ì…ë ¥ì„ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.
    
    ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ì •ë³´:
    1. ì¶”ì¶œëœ í‚¤ì›Œë“œ (ìˆ˜ì • ê°€ëŠ¥)
    2. ê²€ìƒ‰í•  ë…¼ë¬¸ ìˆ˜ ì„ íƒ
    3. ê²€ìƒ‰ ì†ŒìŠ¤ ì„ íƒ
    
    Args:
        state: í˜„ì¬ ì›Œí¬í”Œë¡œìš° ìƒíƒœ
    
    Returns:
        dict: Interrupt ë°ì´í„°ë¥¼ í¬í•¨í•œ ìƒíƒœ ì—…ë°ì´íŠ¸
    """
    keywords = state["extracted_keywords"]
    
    # ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ë©”ì‹œì§€ êµ¬ì„±
    message = f"""
## ğŸ” ê²€ìƒ‰ ì„¤ì • í™•ì¸

ë¶„ì„ëœ í‚¤ì›Œë“œë¥¼ í™•ì¸í•˜ê³  ê²€ìƒ‰ ì„¤ì •ì„ ì„ íƒí•´ì£¼ì„¸ìš”.

### ì¶”ì¶œëœ í‚¤ì›Œë“œ
{', '.join(keywords)}

### ê²€ìƒ‰ ì˜µì…˜
- ê²€ìƒ‰í•  ë…¼ë¬¸ ìˆ˜: 1-10ê°œ ì¤‘ ì„ íƒ
- ê²€ìƒ‰ ì†ŒìŠ¤: arXiv (ê¸°ë³¸)

ìˆ˜ì •ì´ í•„ìš”í•˜ë©´ ì•Œë ¤ì£¼ì„¸ìš”. ê·¸ëŒ€ë¡œ ì§„í–‰í•˜ë ¤ë©´ "í™•ì¸"ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.
    """.strip()
    
    interrupt_data = InterruptData(
        interrupt_type="confirm_keywords",
        message=message,
        options=["1", "2", "3", "4", "5", "6", "7", "8", "9", "10"],
        default_value="3",
        metadata={
            "keywords": keywords,
            "suggested_sources": ["arxiv"]
        }
    )
    
    # ReAct Thought ê¸°ë¡
    thought_content = """
í‚¤ì›Œë“œ ì¶”ì¶œì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. 
ì‚¬ìš©ìì—ê²Œ í™•ì¸ì„ ìš”ì²­í•˜ê³ , ê²€ìƒ‰í•  ë…¼ë¬¸ ìˆ˜ë¥¼ ì„ íƒë°›ì•„ì•¼ í•©ë‹ˆë‹¤.
ì›Œí¬í”Œë¡œìš°ë¥¼ ì¼ì‹œ ì¤‘ì§€í•˜ê³  ì‚¬ìš©ì ì…ë ¥ì„ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.
    """.strip()
    
    new_step = ReActStep(
        step_type="thought",
        content=thought_content
    )
    
    return {
        "interrupt_data": interrupt_data,
        "waiting_for_user": True,
        "react_steps": [new_step]
    }


# ============================================
# ë…¸ë“œ 4: ì‚¬ìš©ì ì‘ë‹µ ì²˜ë¦¬ (process_user_response)
# ============================================

def process_user_response_node(state: AgentState) -> dict:
    """
    ì‚¬ìš©ìì˜ ì‘ë‹µì„ ì²˜ë¦¬í•˜ê³  ê²€ìƒ‰ ì„¤ì •ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    
    ì´ ë…¸ë“œëŠ” ì‚¬ìš©ìê°€ Interruptì— ì‘ë‹µí•œ í›„ ì‹¤í–‰ë©ë‹ˆë‹¤.
    ì‚¬ìš©ìì˜ ì„ íƒì— ë”°ë¼:
    1. í‚¤ì›Œë“œ ìˆ˜ì • (í•„ìš”í•œ ê²½ìš°)
    2. ë…¼ë¬¸ ìˆ˜ ì„¤ì •
    3. ê²€ìƒ‰ ì†ŒìŠ¤ ì„¤ì •
    
    Args:
        state: í˜„ì¬ ì›Œí¬í”Œë¡œìš° ìƒíƒœ (user_response í¬í•¨)
    
    Returns:
        dict: ì—…ë°ì´íŠ¸ëœ ê²€ìƒ‰ ì„¤ì •
    """
    user_response = state.get("user_response", "3")
    
    # ì‚¬ìš©ì ì‘ë‹µ íŒŒì‹±
    # ê°„ë‹¨í•œ êµ¬í˜„: ìˆ«ìë§Œ ìˆìœ¼ë©´ ë…¼ë¬¸ ìˆ˜ë¡œ í•´ì„
    try:
        paper_count = int(user_response)
        paper_count = max(1, min(10, paper_count))  # 1-10 ë²”ìœ„ë¡œ ì œí•œ
    except ValueError:
        paper_count = 3  # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’
    
    # ReAct Observation ê¸°ë¡
    observation_content = f"""
ì‚¬ìš©ì ì‘ë‹µ ì²˜ë¦¬ ì™„ë£Œ:
- ì„ íƒëœ ë…¼ë¬¸ ìˆ˜: {paper_count}
- ê²€ìƒ‰ ì†ŒìŠ¤: arXiv
ê²€ìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤.
    """.strip()
    
    new_step = ReActStep(
        step_type="observation",
        content=observation_content
    )
    
    return {
        "paper_count": paper_count,
        "waiting_for_user": False,
        "interrupt_data": None,
        "react_steps": [new_step]
    }


# ============================================
# ë…¸ë“œ 5: ë…¼ë¬¸ ê²€ìƒ‰ (search_papers)
# ============================================

def search_papers_node(state: AgentState) -> dict:
    """
    ì„¤ì •ëœ í‚¤ì›Œë“œì™€ ì˜µì…˜ìœ¼ë¡œ ë…¼ë¬¸ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    ì´ ë…¸ë“œëŠ” ReAct íŒ¨í„´ì—ì„œ Actionì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.
    arXiv (ê·¸ë¦¬ê³  ë‚˜ì¤‘ì— ë‹¤ë¥¸ ì†ŒìŠ¤ë“¤)ì—ì„œ ë…¼ë¬¸ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    Args:
        state: í˜„ì¬ ì›Œí¬í”Œë¡œìš° ìƒíƒœ
    
    Returns:
        dict: ê²€ìƒ‰ëœ ë…¼ë¬¸ ëª©ë¡ì„ í¬í•¨í•œ ìƒíƒœ ì—…ë°ì´íŠ¸
    """
    keywords = state["extracted_keywords"]
    paper_count = state.get("paper_count", 3)
    domain = state.get("question_domain", None)
    
    # ReAct Action ê¸°ë¡
    action_content = f"""
ë…¼ë¬¸ ê²€ìƒ‰ì„ ì‹¤í–‰í•©ë‹ˆë‹¤:
- í‚¤ì›Œë“œ: {keywords}
- ê²€ìƒ‰ ìˆ˜: {paper_count}
- ë„ë©”ì¸: {domain or 'ì „ì²´'}
- ì†ŒìŠ¤: arXiv
    """.strip()
    
    action_step = ReActStep(
        step_type="action",
        content=action_content
    )
    
    try:
        # arXiv ê²€ìƒ‰ ì‹¤í–‰
        papers = search_arxiv(
            keywords=keywords,
            max_results=paper_count,
            domain=domain
        )
        
        # ReAct Observation ê¸°ë¡
        observation_content = f"""
ê²€ìƒ‰ ì™„ë£Œ: {len(papers)}ê°œì˜ ë…¼ë¬¸ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.
ë…¼ë¬¸ ëª©ë¡:
"""
        for i, paper in enumerate(papers, 1):
            observation_content += f"\n{i}. {paper.title} (ì—°ê´€ì„±: {paper.relevance_score})"
        
        observation_step = ReActStep(
            step_type="observation",
            content=observation_content.strip()
        )
        
        return {
            "papers": papers,  # Annotated[List, operator.add]ì´ë¯€ë¡œ ì¶”ê°€ë¨
            "react_steps": [action_step, observation_step],
            "error_message": None
        }
        
    except Exception as e:
        # ì—ëŸ¬ ë°œìƒ ì‹œ
        error_step = ReActStep(
            step_type="observation",
            content=f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        )
        
        return {
            "react_steps": [action_step, error_step],
            "error_message": str(e)
        }


# ============================================
# ë…¸ë“œ 6: ì—°ê´€ì„± í‰ê°€ (evaluate_relevance)
# ============================================

def evaluate_relevance_node(state: AgentState) -> dict:
    """
    ê²€ìƒ‰ëœ ë…¼ë¬¸ë“¤ì˜ ì—°ê´€ì„±ì„ ì¬í‰ê°€í•˜ê³  í•„í„°ë§í•©ë‹ˆë‹¤.
    
    ì´ ë…¸ë“œëŠ” ê²€ìƒ‰ ê²°ê³¼ ì¤‘ì—ì„œ ì‹¤ì œë¡œ ì‚¬ìš©ì ì§ˆë¬¸ê³¼
    ê´€ë ¨ ìˆëŠ” ë…¼ë¬¸ë§Œ ì„ ë³„í•©ë‹ˆë‹¤.
    
    ì—°ê´€ì„±ì´ ë‚®ì€ ë…¼ë¬¸ì„ ê±¸ëŸ¬ë‚´ì–´ í’ˆì§ˆì„ ë³´ì¥í•©ë‹ˆë‹¤.
    
    Args:
        state: í˜„ì¬ ì›Œí¬í”Œë¡œìš° ìƒíƒœ
    
    Returns:
        dict: í•„í„°ë§ëœ ë…¼ë¬¸ ëª©ë¡
    """
    papers = state.get("papers", [])
    threshold = settings.relevance_threshold
    
    # ì—°ê´€ì„± ì ìˆ˜ê°€ ì„ê³„ê°’ ì´ìƒì¸ ë…¼ë¬¸ë§Œ ì„ íƒ
    relevant_papers = [p for p in papers if p.relevance_score >= threshold]
    
    # ë§Œì•½ í•„í„°ë§ í›„ ë…¼ë¬¸ì´ ì—†ìœ¼ë©´, ìƒìœ„ ë…¼ë¬¸ì´ë¼ë„ í¬í•¨
    if not relevant_papers and papers:
        relevant_papers = papers[:min(3, len(papers))]
    
    # ReAct Thought ê¸°ë¡
    thought_content = f"""
ì—°ê´€ì„± í‰ê°€ ì™„ë£Œ:
- ì „ì²´ ê²€ìƒ‰ ê²°ê³¼: {len(papers)}ê°œ
- ì„ê³„ê°’({threshold}) ì´ìƒ: {len(relevant_papers)}ê°œ
- ì„ ë³„ëœ ë…¼ë¬¸: {[p.title[:30] + '...' for p in relevant_papers]}
    """.strip()
    
    new_step = ReActStep(
        step_type="thought",
        content=thought_content
    )
    
    return {
        "relevant_papers": relevant_papers,
        "react_steps": [new_step]
    }


# ============================================
# ë…¸ë“œ 7: ë…¼ë¬¸ ìš”ì•½ ìƒì„± (summarize_papers)
# ============================================

SUMMARIZE_PROMPT = """
ë‹¤ìŒ ë…¼ë¬¸ì˜ ì´ˆë¡ì„ ì½ê³  í•µì‹¬ ë‚´ìš©ì„ í•œêµ­ì–´ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.

## ë…¼ë¬¸ ì œëª©
{title}

## ì´ˆë¡
{abstract}

## ìš”ì•½ í˜•ì‹ (ë‹¤ìŒ í˜•ì‹ì„ ë”°ë¼ì£¼ì„¸ìš”)

### í•µì‹¬ ì•„ì´ë””ì–´
[ë…¼ë¬¸ì˜ ì£¼ìš” ê¸°ì—¬ì ì„ 2-3ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…]

### ì—°êµ¬ ë°°ê²½ ë° ë¬¸ì œì 
[í•´ê²°í•˜ê³ ì í•˜ëŠ” ë¬¸ì œë¥¼ ì„¤ëª…]

### ì œì•ˆ ë°©ë²•ë¡ 
[ë¬¸ì œ í•´ê²° ì ‘ê·¼ë²•ì„ ì„¤ëª…]

### ì£¼ìš” ì„±ê³¼
[ì‹¤í—˜ ê²°ê³¼ë‚˜ ë‹¬ì„±í•œ ì„±ê³¼ë¥¼ ì„¤ëª…]
"""


def summarize_papers_node(state: AgentState) -> dict:
    """
    ì„ ë³„ëœ ë…¼ë¬¸ë“¤ì˜ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    ê° ë…¼ë¬¸ì— ëŒ€í•´ LLMì„ í˜¸ì¶œí•˜ì—¬ êµ¬ì¡°í™”ëœ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤.
    ì´ ê³¼ì •ì€ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    
    Args:
        state: í˜„ì¬ ì›Œí¬í”Œë¡œìš° ìƒíƒœ
    
    Returns:
        dict: ìš”ì•½ì´ ì¶”ê°€ëœ ë…¼ë¬¸ ëª©ë¡
    """
    relevant_papers = state.get("relevant_papers", [])
    
    if not relevant_papers:
        return {
            "react_steps": [ReActStep(
                step_type="observation",
                content="ìš”ì•½í•  ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤."
            )]
        }
    
    llm = get_llm()  # ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš© (ìš”ì•½ì€ í’ˆì§ˆì´ ì¤‘ìš”)
    
    # ReAct Action ê¸°ë¡
    action_step = ReActStep(
        step_type="action",
        content=f"{len(relevant_papers)}ê°œ ë…¼ë¬¸ì˜ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."
    )
    
    summarized_papers = []
    
    for paper in relevant_papers:
        try:
            prompt = SUMMARIZE_PROMPT.format(
                title=paper.title,
                abstract=paper.abstract
            )
            
            response = llm.invoke([
                HumanMessage(content=prompt)
            ])
            
            # ìš”ì•½ì„ ë…¼ë¬¸ ê°ì²´ì— ì¶”ê°€
            paper.summary = response.content
            summarized_papers.append(paper)
            
        except Exception as e:
            # ê°œë³„ ë…¼ë¬¸ ìš”ì•½ ì‹¤íŒ¨ ì‹œì—ë„ ê³„ì† ì§„í–‰
            paper.summary = f"ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {str(e)}"
            summarized_papers.append(paper)
    
    # ReAct Observation ê¸°ë¡
    observation_step = ReActStep(
        step_type="observation",
        content=f"{len(summarized_papers)}ê°œ ë…¼ë¬¸ì˜ ìš”ì•½ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
    )
    
    return {
        "relevant_papers": summarized_papers,
        "react_steps": [action_step, observation_step]
    }


# ============================================
# ë…¸ë“œ 8: ìµœì¢… ì‘ë‹µ ìƒì„± (generate_response)
# ============================================

FINAL_RESPONSE_PROMPT = """
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ê²€ìƒ‰ëœ ë…¼ë¬¸ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì¢…í•©ì ì¸ ë‹µë³€ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

## ì‚¬ìš©ì ì§ˆë¬¸
{question}

## ê²€ìƒ‰ëœ ë…¼ë¬¸ë“¤
{papers_info}

## ë‹µë³€ í˜•ì‹

ì¹œì ˆí•˜ê³  ìì„¸í•œ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”. ë‹¤ìŒ ìš”ì†Œë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:

1. **ì§ˆë¬¸ì— ëŒ€í•œ ì§ì ‘ì ì¸ ë‹µë³€** (2-3ë¬¸ì¥)
2. **ê´€ë ¨ ì—°êµ¬ ë™í–¥ ìš”ì•½** (ë…¼ë¬¸ë“¤ì˜ ê³µí†µ ì£¼ì œ ë° íŠ¸ë Œë“œ)
3. **ê° ë…¼ë¬¸ ìš”ì•½** (ì´ë¯¸ ìƒì„±ëœ ìš”ì•½ì„ í™œìš©)
4. **ì¶”ê°€ íƒêµ¬ ì œì•ˆ** (ë” ì•Œì•„ë³¼ ë§Œí•œ ì£¼ì œë‚˜ í‚¤ì›Œë“œ)

ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ë˜, ê¸°ìˆ  ìš©ì–´ëŠ” ì˜ì–´ ë³‘ê¸°í•´ì£¼ì„¸ìš”.
"""


def generate_response_node(state: AgentState) -> dict:
    """
    ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    ì´ ë…¸ë“œëŠ” ReAct íŒ¨í„´ì—ì„œ ìµœì¢… Decisionì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.
    ëª¨ë“  ë¶„ì„ê³¼ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ
    ì œê³µí•  ìµœì¢… ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        state: í˜„ì¬ ì›Œí¬í”Œë¡œìš° ìƒíƒœ
    
    Returns:
        dict: ìµœì¢… ì‘ë‹µì„ í¬í•¨í•œ ìƒíƒœ ì—…ë°ì´íŠ¸
    """
    user_question = state["user_question"]
    relevant_papers = state.get("relevant_papers", [])
    error_message = state.get("error_message")
    
    # ì—ëŸ¬ê°€ ìˆìœ¼ë©´ ì—ëŸ¬ ë©”ì‹œì§€ ë°˜í™˜
    if error_message:
        return {
            "final_response": f"ì£„ì†¡í•©ë‹ˆë‹¤. ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_message}",
            "is_complete": True
        }
    
    # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìœ¼ë©´
    if not relevant_papers:
        return {
            "final_response": """
ì£„ì†¡í•©ë‹ˆë‹¤. ì…ë ¥í•˜ì‹  ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë…¼ë¬¸ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.

ë‹¤ìŒì„ ì‹œë„í•´ë³´ì„¸ìš”:
- ë” êµ¬ì²´ì ì¸ í‚¤ì›Œë“œë¡œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”
- ì˜ì–´ í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”
- ë‹¤ë¥¸ ê´€ì ì—ì„œ ì§ˆë¬¸ì„ ë‹¤ì‹œ ì‘ì„±í•´ë³´ì„¸ìš”
            """.strip(),
            "is_complete": True
        }
    
    # ë…¼ë¬¸ ì •ë³´ í¬ë§·íŒ…
    papers_info = ""
    for i, paper in enumerate(relevant_papers, 1):
        papers_info += f"""
### ë…¼ë¬¸ {i}: {paper.title}
- ì €ì: {', '.join(paper.authors[:3])}{'...' if len(paper.authors) > 3 else ''}
- ì¶œíŒì¼: {paper.published_date}
- URL: {paper.url}
- ì—°ê´€ì„± ì ìˆ˜: {paper.relevance_score}

**ìš”ì•½:**
{paper.summary or 'ìš”ì•½ ì—†ìŒ'}

---
"""
    
    # LLMìœ¼ë¡œ ìµœì¢… ì‘ë‹µ ìƒì„±
    llm = get_llm()
    
    prompt = FINAL_RESPONSE_PROMPT.format(
        question=user_question,
        papers_info=papers_info
    )
    
    try:
        response = llm.invoke([
            SystemMessage(content="ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ í•™ìˆ  ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."),
            HumanMessage(content=prompt)
        ])
        
        final_response = response.content
        
    except Exception as e:
        # LLM í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì‘ë‹µ
        final_response = f"""
## ê²€ìƒ‰ ê²°ê³¼

ì§ˆë¬¸: {user_question}

{len(relevant_papers)}ê°œì˜ ê´€ë ¨ ë…¼ë¬¸ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤:

{papers_info}
        """.strip()
    
    # ReAct Decision ê¸°ë¡
    decision_step = ReActStep(
        step_type="thought",
        content="ìµœì¢… ì‘ë‹µ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì›Œí¬í”Œë¡œìš°ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤."
    )
    
    return {
        "final_response": final_response,
        "is_complete": True,
        "react_steps": [decision_step]
    }
