"""
Gradio ì›¹ ì¸í„°í˜ì´ìŠ¤
====================

ì´ íŒŒì¼ì€ ì‚¬ìš©ìê°€ ì‹¤ì œë¡œ ìƒí˜¸ì‘ìš©í•˜ëŠ” ì›¹ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.

ê¸°ì¡´ app.pyì™€ì˜ ì°¨ì´ì :
-----------------------
1. LangGraph ì›Œí¬í”Œë¡œìš°ì™€ í†µí•©
2. Human-in-the-Loop ì§€ì› (ì±„íŒ… í˜•ì‹)
3. ReAct ê³¼ì • ì‹œê°í™”
4. ê°œì„ ëœ UI/UX
"""

import gradio as gr
from typing import List, Tuple, Optional
import json
import uuid

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
from app.graph.workflow import ResearchAssistant
from app.config import get_settings

# ì„¤ì • ë¡œë“œ
settings = get_settings()


# ============================================
# ì „ì—­ ìƒíƒœ ê´€ë¦¬
# ============================================

session_assistants = {}


def get_or_create_assistant(session_id: str) -> ResearchAssistant:
    """ì„¸ì…˜ë³„ ì–´ì‹œìŠ¤í„´íŠ¸ë¥¼ ê°€ì ¸ì˜¤ê±°ë‚˜ ìƒì„±í•©ë‹ˆë‹¤."""
    if session_id not in session_assistants:
        session_assistants[session_id] = ResearchAssistant()
    return session_assistants[session_id]


# ============================================
# ì±„íŒ… ì²˜ë¦¬ í•¨ìˆ˜
# ============================================

def process_message(
    message: str,
    history: List[Tuple[str, str]],
    session_state: dict
) -> Tuple[str, List[Tuple[str, str]], dict]:
    """
    ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•˜ê³  ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    Human-in-the-Loopì„ ì§€ì›í•©ë‹ˆë‹¤.
    """
    
    if not message.strip():
        return "", history, session_state
    
    session_id = session_state.get("session_id", str(uuid.uuid4()))
    session_state["session_id"] = session_id
    
    assistant = get_or_create_assistant(session_id)
    
    waiting_for_input = session_state.get("waiting_for_input", False)
    
    if waiting_for_input:
        # Interruptì— ëŒ€í•œ ì‘ë‹µ ì²˜ë¦¬
        result = assistant.continue_with_response(message)
        
        if result["status"] == "completed":
            response = result["response"]
            session_state["waiting_for_input"] = False
            history.append((message, response))
            
        elif result["status"] == "waiting_for_input":
            response = result["message"]
            history.append((message, response))
            
        else:
            response = f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {result.get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}"
            session_state["waiting_for_input"] = False
            history.append((message, response))
    
    else:
        # ìƒˆë¡œìš´ ì§ˆë¬¸ ì²˜ë¦¬
        result = assistant.start(message, session_id)
        
        if result["status"] == "waiting_for_input":
            response = result["message"]
            
            keywords = result.get("keywords", [])
            if keywords:
                response += f"\n\n**ğŸ”‘ ì¶”ì¶œëœ í‚¤ì›Œë“œ**: {', '.join(keywords)}"
            
            response += "\n\n---\n**ğŸ“Š ê²€ìƒ‰í•  ë…¼ë¬¸ ìˆ˜ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš” (1-10):**"
            
            session_state["waiting_for_input"] = True
            session_state["thread_id"] = result.get("thread_id")
            
            history.append((message, response))
            
        elif result["status"] == "completed":
            response = result["response"]
            history.append((message, response))
            
        else:
            response = f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {result.get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}"
            history.append((message, response))
    
    return "", history, session_state


def quick_search(question: str, paper_count: int) -> str:
    """
    ë¹ ë¥¸ ê²€ìƒ‰ ê¸°ëŠ¥ - Human-in-the-Loop ì—†ì´ ë°”ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    """
    if not question.strip():
        return "âŒ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."
    
    assistant = ResearchAssistant()
    
    try:
        response = assistant.run(question, paper_count=paper_count)
        return response
    except Exception as e:
        return f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


# ============================================
# Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±
# ============================================

def create_gradio_interface() -> gr.Blocks:
    """
    Gradio ì›¹ ì¸í„°í˜ì´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    
    theme = gr.themes.Soft(
        primary_hue="blue",
        secondary_hue="gray",
    )
    
    with gr.Blocks(
        title="ğŸ“š AI Research Assistant",
        theme=theme,
        css="""
        .container { max-width: 1200px; margin: auto; }
        .header { text-align: center; margin-bottom: 20px; }
        """
    ) as demo:
        
        # í—¤ë”
        gr.Markdown("""
        # ğŸ“š AI Research Assistant
        ### í•™ìˆ  ë…¼ë¬¸ ê¸°ë°˜ ì§€ëŠ¥í˜• ì—°êµ¬ ë„ìš°ë¯¸
        
        ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ AIê°€ ê´€ë ¨ ë…¼ë¬¸ì„ ê²€ìƒ‰í•˜ê³  í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•´ë“œë¦½ë‹ˆë‹¤.
        
        **ğŸ”§ ê¸°ìˆ  ìŠ¤íƒ**: LangGraph + ReAct Pattern + Human-in-the-Loop
        
        ---
        """)
        
        # íƒ­ ì¸í„°í˜ì´ìŠ¤
        with gr.Tabs():
            
            # íƒ­ 1: ëŒ€í™”í˜• ê²€ìƒ‰
            with gr.Tab("ğŸ’¬ ëŒ€í™”í˜• ê²€ìƒ‰", id="chat"):
                
                gr.Markdown("""
                **ì‚¬ìš© ë°©ë²•:**
                1. ì—°êµ¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”
                2. AIê°€ í‚¤ì›Œë“œë¥¼ ë¶„ì„í•˜ê³  í™•ì¸ì„ ìš”ì²­í•©ë‹ˆë‹¤
                3. ê²€ìƒ‰í•  ë…¼ë¬¸ ìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš” (1-10 ì‚¬ì´ ìˆ«ì ì…ë ¥)
                4. ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”
                """)
                
                session_state = gr.State({
                    "session_id": None,
                    "waiting_for_input": False,
                    "thread_id": None
                })
                
                chatbot = gr.Chatbot(
                    label="ëŒ€í™”",
                    height=500,
                    show_label=False,
                    bubble_full_width=False
                )
                
                with gr.Row():
                    chat_input = gr.Textbox(
                        label="ë©”ì‹œì§€ ì…ë ¥",
                        placeholder="ì—°êµ¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”... (ì˜ˆ: ììœ¨ì£¼í–‰ LiDAR ì„¼ì„œ ê¸°ìˆ )",
                        lines=2,
                        scale=4
                    )
                    send_btn = gr.Button("ì „ì†¡", variant="primary", scale=1)
                
                gr.Examples(
                    examples=[
                        "ììœ¨ì£¼í–‰ ìë™ì°¨ì˜ LiDAR ì„¼ì„œ ë°ì´í„° ì²˜ë¦¬ ìµœì‹  ê¸°ë²•",
                        "Transformer ì•„í‚¤í…ì²˜ë¥¼ í™œìš©í•œ ìì—°ì–´ ì²˜ë¦¬",
                        "ë”¥ëŸ¬ë‹ ê¸°ë°˜ ì˜ë£Œ ì˜ìƒ ë¶„ì„ ì—°êµ¬ ë™í–¥",
                        "ê°•í™”í•™ìŠµì˜ ë¡œë´‡ ì œì–´ ì‘ìš©",
                    ],
                    inputs=chat_input,
                    label="ì˜ˆì‹œ ì§ˆë¬¸"
                )
                
                send_btn.click(
                    fn=process_message,
                    inputs=[chat_input, chatbot, session_state],
                    outputs=[chat_input, chatbot, session_state]
                )
                
                chat_input.submit(
                    fn=process_message,
                    inputs=[chat_input, chatbot, session_state],
                    outputs=[chat_input, chatbot, session_state]
                )
            
            # íƒ­ 2: ë¹ ë¥¸ ê²€ìƒ‰
            with gr.Tab("ğŸ” ë¹ ë¥¸ ê²€ìƒ‰", id="quick"):
                
                gr.Markdown("""
                **ë¹ ë¥¸ ê²€ìƒ‰ ëª¨ë“œ:**
                ë…¼ë¬¸ ìˆ˜ë¥¼ ë¯¸ë¦¬ ì„ íƒí•˜ê³  ë°”ë¡œ ê²€ìƒ‰ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
                ë‹¨ê³„ë³„ í™•ì¸ ê³¼ì • ì—†ì´ ë¹ ë¥´ê²Œ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                """)
                
                with gr.Row():
                    with gr.Column(scale=3):
                        quick_input = gr.Textbox(
                            label="ğŸ“ ì—°êµ¬ ì§ˆë¬¸",
                            placeholder="ê²€ìƒ‰í•˜ê³  ì‹¶ì€ ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”...",
                            lines=3
                        )
                    
                    with gr.Column(scale=1):
                        paper_slider = gr.Slider(
                            minimum=1,
                            maximum=10,
                            value=3,
                            step=1,
                            label="ğŸ”¢ ë…¼ë¬¸ ìˆ˜"
                        )
                        search_btn = gr.Button(
                            "ğŸ” ê²€ìƒ‰",
                            variant="primary",
                            size="lg"
                        )
                
                quick_output = gr.Markdown(
                    label="ê²€ìƒ‰ ê²°ê³¼",
                    value="*ê²€ìƒ‰ ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤*"
                )
                
                search_btn.click(
                    fn=quick_search,
                    inputs=[quick_input, paper_slider],
                    outputs=quick_output
                )
            
            # íƒ­ 3: ì •ë³´
            with gr.Tab("â„¹ï¸ ì •ë³´", id="info"):
                
                gr.Markdown("""
                ## ğŸ“– AI Research Assistant ì†Œê°œ
                
                ì´ ë„êµ¬ëŠ” **LangGraph**ì™€ **ReAct íŒ¨í„´**ì„ í™œìš©í•œ 
                í•™ìˆ  ë…¼ë¬¸ ê²€ìƒ‰ ë° ìš”ì•½ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
                
                ### âœ¨ ì£¼ìš” ê¸°ëŠ¥
                
                1. **ì§ˆë¬¸ ë¶„ì„**: AIê°€ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤
                2. **Human-in-the-Loop**: ì‚¬ìš©ìê°€ ê²€ìƒ‰ ì„¤ì •ì„ í™•ì¸í•˜ê³  ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
                3. **ë…¼ë¬¸ ê²€ìƒ‰**: arXivì—ì„œ ê´€ë ¨ ë…¼ë¬¸ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤
                4. **ì—°ê´€ì„± í‰ê°€**: ê²€ìƒ‰ ê²°ê³¼ì˜ ì—°ê´€ì„±ì„ í‰ê°€í•˜ì—¬ í•„í„°ë§í•©ë‹ˆë‹¤
                5. **ìš”ì•½ ìƒì„±**: ê° ë…¼ë¬¸ì˜ í•µì‹¬ ë‚´ìš©ì„ êµ¬ì¡°í™”ëœ í˜•ì‹ìœ¼ë¡œ ìš”ì•½í•©ë‹ˆë‹¤
                
                ### ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ
                
                - **LangGraph**: ì›Œí¬í”Œë¡œìš° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
                - **ReAct íŒ¨í„´**: Thought-Action-Observation êµ¬ì¡°
                - **OpenAI GPT-4o**: ì§ˆë¬¸ ë¶„ì„ ë° ìš”ì•½ ìƒì„±
                - **arXiv API**: ë…¼ë¬¸ ê²€ìƒ‰
                - **Gradio**: ì›¹ ì¸í„°í˜ì´ìŠ¤
                
                ### ğŸ”„ ì›Œí¬í”Œë¡œìš°
                
                ```
                ì§ˆë¬¸ ì…ë ¥ â†’ ì§ˆë¬¸ ë¶„ì„ â†’ í‚¤ì›Œë“œ ì¶”ì¶œ
                    â†“
                [Human-in-the-Loop: ì‚¬ìš©ì í™•ì¸]
                    â†“
                ë…¼ë¬¸ ê²€ìƒ‰ â†’ ì—°ê´€ì„± í‰ê°€ â†’ í•„í„°ë§
                    â†“
                ìš”ì•½ ìƒì„± â†’ ìµœì¢… ì‘ë‹µ
                ```
                
                ### ğŸ“ ReAct íŒ¨í„´ì´ë€?
                
                ReActëŠ” **Reasoning + Acting**ì˜ ì•½ìë¡œ, AIê°€ ë‹¤ìŒ ê³¼ì •ì„ ëª…ì‹œì ìœ¼ë¡œ ìˆ˜í–‰í•©ë‹ˆë‹¤:
                
                1. **Thought (ìƒê°)**: í˜„ì¬ ìƒí™©ì„ ë¶„ì„í•˜ê³  ë‹¤ìŒ í–‰ë™ì„ ê³„íš
                2. **Action (í–‰ë™)**: ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜ ì‘ì—…ì„ ì‹¤í–‰
                3. **Observation (ê´€ì°°)**: í–‰ë™ì˜ ê²°ê³¼ë¥¼ ê´€ì°°í•˜ê³  ê¸°ë¡
                
                ì´ ê³¼ì •ì„ ë°˜ë³µí•˜ì—¬ ë³µì¡í•œ ë¬¸ì œë¥¼ ë‹¨ê³„ì ìœ¼ë¡œ í•´ê²°í•©ë‹ˆë‹¤.
                
                ### ğŸš€ í–¥í›„ ê³„íš
                
                - ë‹¤ì¤‘ ë…¼ë¬¸ ì†ŒìŠ¤ ì§€ì› (Semantic Scholar, PubMed ë“±)
                - ì›¹ ê²€ìƒ‰ í†µí•© (Tavily API)
                - Vector DB ì—°ë™ (Weaviate)
                - Long-term Memory ê¸°ëŠ¥
                - êµ­ë‚´ ë…¼ë¬¸ ê²€ìƒ‰ (DBpia, RISS)
                
                ---
                
                **ê°œë°œì**: AI Hackathon Project  
                **ë²„ì „**: 2.0
                """)
        
        # í‘¸í„°
        gr.Markdown("""
        ---
        <center>
        Made with â¤ï¸ using LangGraph + Gradio | 
        <a href="https://arxiv.org" target="_blank">arXiv</a>
        </center>
        """)
    
    return demo


# ============================================
# ë©”ì¸ ì‹¤í–‰
# ============================================

def main():
    """Gradio ì•±ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    demo = create_gradio_interface()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False
    )


if __name__ == "__main__":
    main()
