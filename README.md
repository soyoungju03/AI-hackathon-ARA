---
title: AI Research Assistant
emoji: 🤖
colorFrom: blue
colorTo: purple
sdk: gradio
sdk_version: 4.14.0
app_file: app.py
pinned: false
---

# 📚 AI Research Assistant

학술 논문 기반 지능형 연구 도우미 - LangGraph + ReAct Pattern + Human-in-the-Loop + Semantic Search

[![Hugging Face Spaces](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/spaces/Jusoyoung/AI-Research-Assistant)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## 🎯 프로젝트 소개

AI Research Assistant는 사용자의 기술 및 학술 질문을 분석하여 관련 논문을 검색하고, AI가 핵심 내용을 요약 정리해주는 지능형 연구 도우미입니다. 단순한 키워드 매칭을 넘어서 의미 기반 검색을 통해 진정으로 관련성 높은 논문을 찾아냅니다.

### 주요 특징

- **🧠 ReAct 패턴**: Thought-Action-Observation 구조로 AI의 사고 과정을 투명하게 보여줍니다
- **👤 Human-in-the-Loop**: 사용자가 검색 과정에 개입하여 결과의 품질을 향상시킵니다
- **🔄 LangGraph 워크플로우**: 복잡한 작업을 체계적으로 관리하는 상태 기반 워크플로우입니다
- **🎯 의미 기반 검색**: Sentence Transformers를 활용하여 개념적으로 유사한 논문을 찾아냅니다
- **📊 정량적 연관성 평가**: 코사인 유사도를 계산하여 객관적인 관련성 점수를 제공합니다

## 🛠️ 기술 스택

| 구분 | 기술 |
|------|------|
| 오케스트레이션 | LangGraph |
| AI 패턴 | ReAct (Reasoning + Acting) |
| LLM | OpenAI GPT-4o |
| 임베딩 | Sentence Transformers (all-MiniLM-L6-v2) |
| 논문 검색 | arXiv API |
| 웹 인터페이스 | Gradio |
| 언어 | Python 3.10+ |

## 🎯 의미 기반 검색 시스템

본 시스템의 핵심 기술인 의미 기반 검색은 단순한 키워드 매칭을 넘어서 텍스트의 의미를 이해합니다. 이것이 어떻게 작동하는지 살펴보겠습니다.

### 작동 원리

사용자가 질문을 입력하면, 시스템은 질문과 각 논문을 고차원 벡터 공간에 매핑합니다. 이 과정을 임베딩이라고 부릅니다. 임베딩된 벡터들 사이의 거리를 측정함으로써, 의미적으로 얼마나 유사한지 정량적으로 평가할 수 있습니다.

예를 들어 사용자가 "neural networks for image processing"이라고 검색하면, 시스템은 "CNN" 또는 "convolutional"이라는 정확한 단어가 없어도 개념적으로 관련된 논문들을 찾아냅니다. 왜냐하면 이 용어들이 벡터 공간에서 가까운 위치에 있기 때문입니다.

### 기술 세부사항

우리는 Sentence Transformers 라이브러리의 all-MiniLM-L6-v2 모델을 사용합니다. 이 모델은 다음과 같은 특징을 가지고 있습니다. 먼저 384차원의 벡터를 생성하므로 메모리 효율적입니다. CPU에서도 빠르게 작동하므로 실시간 검색이 가능합니다. 영어에 최적화되어 있지만 다국어도 어느 정도 지원합니다.

논문의 관련성을 평가할 때, 제목에 더 큰 가중치를 둡니다. 구체적으로 제목을 두 번 포함하고 초록을 한 번 포함하여 문서 텍스트를 구성합니다. 이렇게 하면 제목의 키워드가 유사도 계산에 더 큰 영향을 미치게 됩니다.

유사도 측정에는 코사인 유사도를 사용합니다. 코사인 유사도는 두 벡터 사이의 각도를 측정하는 방법으로, 0에서 1 사이의 값을 가집니다. 1에 가까울수록 매우 유사하고, 0에 가까울수록 관련성이 적습니다. 우리는 임계값을 0.6으로 설정하여, 이 값 이상인 논문만 최종 결과에 포함시킵니다.

### 전통적인 검색과의 비교

전통적인 키워드 기반 검색은 정확한 단어 매칭에 의존합니다. 사용자가 "machine learning"이라고 검색하면 해당 단어가 포함된 문서만 찾습니다. 하지만 의미 기반 검색은 "neural networks", "deep learning", "artificial intelligence" 같은 관련 개념들도 함께 찾아냅니다.

이것은 특히 학술 연구에서 중요합니다. 같은 개념을 표현하는 방법이 여러 가지 있고, 연구자들마다 다른 용어를 사용하기 때문입니다. 의미 기반 검색은 이러한 용어의 다양성을 극복하고, 실제로 관련된 연구를 놓치지 않도록 도와줍니다.

## 🔄 워크플로우

시스템의 전체 워크플로우는 다음과 같이 진행됩니다. 각 단계는 명확한 목적을 가지고 있으며, 사용자와의 상호작용을 통해 검색의 정확도를 높입니다.
```
┌─────────────────────────────────────────────────────────────┐
│                    사용자 질문 입력                          │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────┐
│  [Thought] 질문 분석                                        │
│  AI가 질문의 의도를 파악하고 핵심 키워드를 추출합니다         │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────┐
│  [Action] 키워드 추출                                       │
│  Keywords: ["autonomous driving", "LiDAR", "point cloud"]   │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────┐
│  🛑 [INTERRUPT 1] Human-in-the-Loop                        │
│  추출된 키워드를 사용자가 확인하고 수정할 수 있습니다          │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────┐
│  🛑 [INTERRUPT 2] 논문 수 선택                             │
│  검색할 논문의 개수를 사용자가 직접 선택합니다                │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────┐
│  [Action] 논문 검색 (arXiv API)                            │
│  선택된 개수만큼 arXiv에서 논문을 검색합니다                  │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────┐
│  [Observation] 의미 기반 연관성 평가                        │
│  Sentence Transformers로 각 논문의 유사도를 계산합니다       │
│  논문 1: 0.92 ✓ | 논문 2: 0.85 ✓ | 논문 3: 0.45 ✗          │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────┐
│  [Action] 선별된 논문 요약 생성                             │
│  임계값 이상인 논문들의 핵심 내용을 GPT-4로 요약합니다        │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────┐
│  [Response] 최종 응답 제공                                  │
│  요약된 내용을 바탕으로 사용자 질문에 답변합니다              │
└─────────────────────────────────────────────────────────────┘
```

## 🚀 시작하기

로컬 환경에서 프로젝트를 실행하는 방법을 안내합니다. 각 단계를 순서대로 따라하시면 문제없이 실행할 수 있습니다.

### 1. 저장소 클론

먼저 GitHub에서 프로젝트를 복제합니다.
```bash
git clone https://github.com/soyoungju03/AI-hackathon-ARA.git
cd AI-hackathon-ARA
```

### 2. 가상 환경 생성 (권장)

가상 환경을 사용하면 프로젝트의 의존성을 격리할 수 있습니다.
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# 또는
venv\Scripts\activate  # Windows
```

### 3. 의존성 설치

requirements.txt에 정의된 모든 라이브러리를 설치합니다.
```bash
pip install -r requirements.txt
```

Sentence Transformers를 처음 실행하면 모델을 자동으로 다운로드합니다. 이 과정은 몇 분 정도 걸릴 수 있습니다.

### 4. 환경 변수 설정

OpenAI API 키를 설정해야 합니다. 프로젝트 루트에 .env 파일을 만들고 다음과 같이 입력하세요.
```
OPENAI_API_KEY=sk-your-api-key-here
```

OpenAI API 키는 platform.openai.com에서 발급받을 수 있습니다.

### 5. 앱 실행

모든 설정이 완료되었으면 앱을 실행합니다.
```bash
python app.py
```

브라우저에서 http://localhost:7860 주소로 접속하면 AI Research Assistant를 사용할 수 있습니다.

## 💡 사용 방법

시스템은 두 가지 모드로 사용할 수 있습니다. 대화형 검색은 각 단계마다 확인을 받아 정확도를 높이고, 빠른 검색은 자동으로 진행하여 시간을 절약합니다.

### 대화형 검색 (권장)

대화형 검색은 Human-in-the-Loop 패턴을 활용하여 최고의 검색 품질을 제공합니다. 다음 순서로 진행됩니다.

첫 번째 단계에서 연구하고 싶은 주제를 자연어로 입력합니다. 예를 들어 "자율주행 자동차의 LiDAR 센서 기술 최신 동향"이라고 입력할 수 있습니다. 복잡한 검색 쿼리 문법을 몰라도 괜찮습니다. 평소 말하는 것처럼 질문하면 됩니다.

두 번째 단계에서 AI가 추출한 키워드를 확인합니다. 시스템이 "autonomous driving", "LiDAR sensor", "point cloud processing" 같은 키워드를 제안하면, 이것이 적절한지 판단합니다. 키워드가 잘 추출되었다면 "확인"을 입력하고, 다시 분석이 필요하다면 "다시"를 입력합니다.

세 번째 단계에서 검색할 논문의 개수를 선택합니다. 1부터 10 사이의 숫자를 입력할 수 있습니다. 빠른 개요를 원한다면 3개 정도가 적당하고, 깊이 있는 조사를 원한다면 7개 이상을 선택하면 됩니다.

마지막으로 시스템이 논문을 검색하고 의미 기반 평가를 수행한 후, 관련성 높은 논문들의 요약과 종합적인 답변을 제공합니다. 각 논문의 유사도 점수도 함께 표시되므로, 얼마나 관련성이 높은지 객관적으로 확인할 수 있습니다.

### 빠른 검색

빠른 검색 모드는 Interrupt 없이 자동으로 진행됩니다. 질문을 입력하고 논문 수를 슬라이더로 선택한 후 검색 버튼을 클릭하면, 시스템이 모든 단계를 자동으로 수행하고 결과를 보여줍니다. 시간이 부족할 때 유용합니다.

## 📁 프로젝트 구조

프로젝트는 체계적인 구조로 구성되어 있습니다. 각 디렉토리와 파일은 명확한 역할을 가지고 있습니다.
```
AI-Research-Assistant/
│
├── app.py                      # Gradio 인터페이스를 실행하는 메인 진입점
├── requirements.txt            # 프로젝트가 의존하는 Python 라이브러리 목록
├── .env.example               # 환경 변수 설정 예시 파일
│
├── app/
│   ├── __init__.py
│   ├── config.py              # 전역 설정을 관리하는 모듈
│   │
│   ├── graph/
│   │   ├── state.py           # LangGraph의 상태 정의
│   │   ├── nodes.py           # 워크플로우의 각 노드 구현
│   │   └── workflow.py        # 전체 워크플로우 구성 및 라우팅
│   │
│   └── tools/
│       ├── embeddings.py      # Sentence Transformers 임베딩 모듈
│       └── paper_search/
│           └── arxiv_tool.py  # arXiv API 클라이언트
│
└── README.md                   # 프로젝트 문서 (현재 파일)
```

## 🔧 Hugging Face Spaces 배포

이 프로젝트는 Hugging Face Spaces에 배포되어 있습니다. 배포 과정에서 중요한 설정들을 안내합니다.

### 환경 변수 설정

Hugging Face Spaces에서 애플리케이션이 작동하려면 OpenAI API 키를 환경 변수로 설정해야 합니다. Space 페이지의 Settings 탭으로 이동하여 Repository secrets 섹션을 찾습니다. 여기서 New secret 버튼을 클릭하고 다음과 같이 입력합니다.

Name 필드에는 정확하게 OPENAI_API_KEY를 입력합니다. 대소문자가 정확히 일치해야 합니다. Value 필드에는 여러분의 실제 OpenAI API 키를 붙여넣습니다. sk-로 시작하는 긴 문자열입니다. 이렇게 하면 코드에 API 키를 직접 포함하지 않고도 안전하게 사용할 수 있습니다.

### 빌드 과정

코드를 Hugging Face에 푸시하면 자동으로 빌드가 시작됩니다. Sentence Transformers 모델을 처음 사용할 때는 모델 파일을 다운로드해야 하므로 빌드 시간이 조금 더 걸릴 수 있습니다. 일반적으로 5분에서 10분 정도 소요됩니다.

빌드가 완료되면 App 탭에서 실제로 작동하는 인터페이스를 확인할 수 있습니다. 만약 문제가 발생한다면 Logs 탭에서 자세한 에러 메시지를 확인할 수 있습니다.

## 📝 주요 개념 설명

프로젝트에서 사용하는 핵심 개념들을 자세히 설명합니다. 이 개념들을 이해하면 시스템의 작동 방식을 더 깊이 파악할 수 있습니다.

### ReAct 패턴이란?

ReAct는 Reasoning과 Acting의 합성어입니다. 이것은 AI가 문제를 해결하는 과정을 명시적으로 표현하는 패러다임입니다. 사람이 문제를 해결할 때 "먼저 이것을 해야겠다"고 생각하고, 실제로 행동하고, 결과를 관찰하는 것처럼, AI도 같은 방식으로 작동하도록 만드는 것입니다.

ReAct 패턴은 세 단계로 구성됩니다. Thought 단계에서는 현재 상황을 분석하고 다음에 무엇을 해야 할지 계획합니다. Action 단계에서는 실제로 도구를 사용하거나 작업을 실행합니다. Observation 단계에서는 행동의 결과를 관찰하고 기록합니다. 이 세 단계를 반복하면서 복잡한 문제를 점진적으로 해결해 나갑니다.

이 패턴의 장점은 AI의 사고 과정이 투명하다는 것입니다. 사용자는 AI가 왜 그런 결정을 내렸는지, 어떤 정보를 바탕으로 판단했는지 명확하게 볼 수 있습니다. 이것은 신뢰성을 높이고, 문제가 발생했을 때 디버깅을 쉽게 만듭니다.

### Human-in-the-Loop이란?

Human-in-the-Loop은 AI 워크플로우 중간에 사람이 개입할 수 있는 구조입니다. 완전히 자동화된 시스템과 달리, 중요한 결정 지점에서 사용자에게 확인을 받거나 선택을 요청합니다.

우리 시스템에서는 두 곳에서 Human-in-the-Loop이 발생합니다. 첫 번째는 키워드 추출 후입니다. AI가 추출한 키워드가 정확한지 사용자가 확인합니다. 만약 키워드가 적절하지 않다면 "다시"를 선택하여 재분석을 요청할 수 있습니다. 두 번째는 논문 개수 선택입니다. 사용자가 직접 검색할 논문의 수를 결정함으로써, 검색의 범위를 조절할 수 있습니다.

이 접근법의 장점은 여러 가지입니다. 첫째, 검색 결과의 정확도가 높아집니다. AI만으로는 사용자의 정확한 의도를 파악하기 어려울 수 있지만, 사용자의 피드백을 받으면 훨씬 정확해집니다. 둘째, 사용자가 검색 과정을 이해하고 통제할 수 있습니다. 블랙박스처럼 작동하는 것이 아니라, 각 단계를 확인하면서 진행할 수 있습니다.

### 벡터 임베딩과 코사인 유사도

벡터 임베딩은 텍스트를 숫자의 배열로 변환하는 기술입니다. 우리가 사용하는 모델은 텍스트를 384개의 숫자로 이루어진 벡터로 변환합니다. 이 벡터는 텍스트의 의미를 수학적으로 표현한 것입니다.

비슷한 의미를 가진 텍스트들은 벡터 공간에서 가까운 위치에 놓입니다. 예를 들어 "machine learning"과 "deep learning"은 벡터 공간에서 가까이 있고, "machine learning"과 "cooking recipe"는 멀리 떨어져 있습니다.

코사인 유사도는 두 벡터 사이의 각도를 측정하는 방법입니다. 벡터들이 같은 방향을 가리키면 유사도가 1에 가깝고, 반대 방향이면 -1에 가깝습니다. 직각을 이루면 0입니다. 우리는 이 값을 0에서 1 사이로 정규화하여 사용합니다.

이 기술을 사용하면 단어가 정확히 일치하지 않아도 의미가 비슷한 문서를 찾을 수 있습니다. 이것이 전통적인 키워드 검색보다 훨씬 강력한 이유입니다.

---

**개발자**: AI Hackathon Team  
**라이선스**: MIT  
**문의**: 프로젝트 이슈 페이지를 통해 질문하실 수 있습니다